
---
title: "1. Classification Dimensions Analysis"
format: html
---

## Introduction

This report presents a classification of students based on the dimensions of self-compassion, burnout, and perceived social support.

```{python}
import openpyxl
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import chi2_contingency
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from statsmodels.graphics.mosaicplot import mosaic
```

```{python}
df = pd.read_excel('./source/project1/DATA_Coaches.xlsx',engine='openpyxl')
```

```{python}
df.describe()
```

## Preparación de datos:
Aplicación de un filtro de exclusión para descartar registros que tengan valores fuera del rango de 1 a 5

```{python}
# Definir rango válido de 1 a 5
valid_range = set(range(1, 6))
# Función para filtrar filas según el rango válido
def is_valid(row):
    return all(value in valid_range for value in row)
# Aplicar la función de filtro a cada fila.
df_cleaned = df[df.apply(is_valid, axis=1)]
df_cleaned.describe()
```

## Función para invertir la puntuación
Función para invertir la puntuación de los ítems de las escalas incorporadas en la base de datos “DATA_coaches”. A pesar que en esta base de datos todas las escalas tienen el mismo rango en la escala ordinal (de 1 a 5 puntos) haced que la función permita trabajar con cualquier escala ordinal a la que se le quiera invertir la puntuación.

```{python}
def invert_values(df, value_max, value_min, columns_to_invert):
    df_inverted = df.copy()
    df_inverted[columns_to_invert] = value_max + value_min - df[columns_to_invert]
    return df_inverted
```

Utilizad la función anterior para invertir los ítems descritos en la Tabla 1 cuya codificación reza como inversa. Hecho esto, guardad estas nuevas variables sobre las originales.

```{python}
value_max = df_cleaned.max().max()
value_min = df_cleaned.min().min()

# Columns to apply the function on
columns_to_invert = [
't1scs1', 't1scs4', 't1scs8', 't1scs9', 't1scs11', 't1scs12', 
't2scs1', 't2scs4', 't2scs8', 't2scs9', 't2scs11', 't2scs12', 
't3scs1', 't3scs4', 't3scs8', 't3scs9', 't3scs11', 't3scs12', 
't1cbq1', 't1cbq14',
't2cbq1', 't2cbq14', 
't3cbq1', 't3cbq14']

# Invert values for specified columns using the function
df_inverted = invert_values(df_cleaned, value_max, value_min, columns_to_invert)

df_inverted.describe()
```

Los valores máximo y mínimo se mantuvieron iguales y se cambió la media.
Prueba para comparar las escalas en la primera línea del df

```{python}
df_cleaned.loc[:0]
```

```{python}
df_inverted.loc[:0]
```

Se observa que para las variables seleccionadas, los valores se invirtieron:
- Valor 1 cambió al valor 5
- Valor 2 cambió al valor 4
- Valor 3 sigue siendo el mismo
- Valor 4 cambió al valor 2
- Valor 5 cambió al valor 1

Reemplezando los valores en el df orginal

```{python}
df = df_inverted
```

Calculad las puntuaciones totales de las escalas (autocompasión, burnout y apoyo social percibido). Guardad estas nuevas variables en la base de datos.


```{python}
autocompasion1 = df.filter(regex='^t1scs')
autocompasion2 = df.filter(regex='^t2scs')
autocompasion3 = df.filter(regex='^t3scs')
burnout1 = df.filter(regex='^t1cbq')
burnout2 = df.filter(regex='^t2cbq')
burnout3 = df.filter(regex='^t3cbq')
apoyo_social1 = df.filter(regex='^t1ssq')
apoyo_social2 = df.filter(regex='^t2ssq')
apoyo_social3 = df.filter(regex='^t3ssq')
```

```{python}
df['autocompasion1'] = autocompasion1.sum(axis=1)
df['autocompasion2'] = autocompasion2.sum(axis=1)
df['autocompasion3'] = autocompasion3.sum(axis=1)
df['burnout1'] = burnout1.sum(axis=1)
df['burnout2'] = burnout2.sum(axis=1)
df['burnout3'] = burnout3.sum(axis=1)
df['apoyo_social1'] = apoyo_social1.sum(axis=1)
df['apoyo_social2'] = apoyo_social2.sum(axis=1)
df['apoyo_social3'] = apoyo_social3.sum(axis=1)
df.head()
```
Con las nuevas variables calculadas en el apartado anterior, haced una descripción estadística de las mismas en los tres momentos de estudio. Una posibilidad de tabla resumen sería la plantilla mostrada en la Tabla 2.
```{python}
df_new = df[['autocompasion1', 'burnout1', 'apoyo_social1',
             'autocompasion2', 'burnout2', 'apoyo_social2',
             'autocompasion3', 'burnout3', 'apoyo_social3']]
```

```{python}
stat = df_new.describe()
stat
```
## Evolución a lo largo del tiempo
Complementad el análisis anterior con gráficos adecuados que permitan evaluar la evolución de las 3 dimensiones a lo largo del tiempo. 

```{python}
mean_values_autocomp1 = stat.loc['mean', 'autocompasion1']
mean_values_burnout1 = stat.loc['mean', 'burnout1']
mean_values_apoyo1 = stat.loc['mean', 'apoyo_social1']
mean_values_autocomp2 = stat.loc['mean', 'autocompasion2']
mean_values_burnout2 = stat.loc['mean', 'burnout2']
mean_values_apoyo2 = stat.loc['mean', 'apoyo_social2']
mean_values_autocomp3 = stat.loc['mean', 'autocompasion3']
mean_values_burnout3 = stat.loc['mean', 'burnout3']
mean_values_apoyo3 = stat.loc['mean', 'apoyo_social3']
```

```{python}
# Create a new DataFrame with the mean values
mean_df = pd.DataFrame({
    'autocompasion': [mean_values_autocomp1, mean_values_autocomp2, mean_values_autocomp3],
    'burnout': [mean_values_burnout1, mean_values_burnout2, mean_values_burnout3],
    'apoyo_social': [mean_values_apoyo1, mean_values_apoyo2, mean_values_apoyo3]
}, index=['Línea Base', '3 Meses', '6 Meses'])
mean_df
```

```{python}
# Plotting with seaborn
plt.figure(figsize=(8, 6))
for column in mean_df.columns:
    sns.lineplot(x=mean_df.index, y=mean_df[column], marker='o',label=column)
    for i, value in enumerate(mean_df[column]):
        plt.annotate(f'{value:.2f}', (mean_df.index[i], value), textcoords="offset points", xytext=(0,5), ha='center', fontsize=8)


plt.title('Media de las dimensiones a lo largo del tiempo')
plt.ylabel('Media')
plt.legend()
plt.show()
```

Autocompasión e Burnout: Con relación a la línea base, se observa que el promedio aumenta en 3 meses y luego disminuye en 6 meses.

Apoyo Social: Con relación a la línea base, se observa que el promedio disminuye en 3 meses y luego aumenta en 6 meses.

Incluso con la dimensión de apoyo social reduciendo el promedio en 3 meses, ambas dimensiones terminaron en 6 meses con un promedio superior al de referencia.

## Boxplots for Each Dimension Over Time

```{python}
# Create separate boxplots for each dimension
fig, axes = plt.subplots(ncols=3, figsize=(18, 6))

dimensions = ['autocompasion', 'burnout', 'apoyo_social']

for i, dim in enumerate(dimensions):
    cols = [col for col in df_new.columns if dim in col]
    df_dim = df_new[cols]
    
    # Melt the DataFrame for boxplot
    df_dim_melted = pd.melt(df_dim, var_name='Time', value_name='Value')

    # Create a boxplot for the current dimension
    ax = sns.boxplot(x='Time', y='Value', data=df_dim_melted, ax=axes[i])
    ax.set_title(f'Boxplot for {dim.capitalize()} Over Time')
    ax.set_xlabel('Time')
    ax.set_ylabel(f'{dim} Value')

plt.tight_layout()
plt.show()
```

Los diagramas de caja anteriores muestran que los datos mantuvieron el mismo patrón a lo largo del tiempo. Lo que llama la atención en este análisis son los valores atípicos.

#### Autocompassion:
- Los valores atípicos aumentaron con el tiempo, tanto para valores altos como bajos. Esto muestra que para algunas personas hubo un gran cambio en la autocompasión a lo largo del tiempo.

#### Burnout:
- Los valores atípicos aumentaron con el tiempo hasta alcanzar valores de aproximadamente 70. Esto muestra que para algunas personas hubo un aumento en el agotamiento con el tiempo.

#### Apoyo Social:
- Los valores atípicos disminuyeron, pero los valores atípicos que aparecieron tuvieron valores más bajos con el tiempo. Esto muestra que para unas pocas personas hubo una gran disminución en el apoyo social con el tiempo.

## Correlation Matrix
Estudiad todas las posibles correlaciones entre las dimensiones obtenidas en los apartados anteriores con indicadores adecuados y de forma separada para cada momento. Complementad estos análisis sobre correlaciones con gráficos adecuados.

```{python}
correlation_matrix = df_new.corr()
correlation_matrix
```

```{python}
# Plot a heatmap for better visualization of correlations
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix')
plt.show()
```
La correlación negativa más fuerte (-0,35) se observó entre "apoyo_social1" y "burnout2". La segunda correlación negativa más grande (-0,33) se produce entre "apoyo_social1" y "burnout1", seguida de la tercera correlación negativa más grande (-0,32) entre "apoyo_social2" y "burnout2".

La correlación positiva más significativa (0,80) se encontró entre "apoyo_social1" y "apoyo_social3". La segunda correlación positiva más alta (0,78) se observa entre "burnout2" y "burnout3", y la tercera correlación positiva más alta (0,77) es entre "apoyo_social1" y "apoyo_social2".

En cuanto a las tendencias, cuando disminuye la percepción de apoyo social, hay una tendencia asociada a que el nivel de burnout disminuya, tanto en el mismo momento como en los tres meses siguientes. Por el contrario, cuando aumenta el apoyo social percibido, a esta tendencia le sigue un aumento continuo en los meses siguientes. De manera similar, un aumento en el nivel de burnout tiende a ir seguido de un aumento durante los próximos tres meses.

Estos patrones sugieren una fuerte asociación entre la percepción de apoyo social y el nivel de agotamiento. Cuando no hay signos de agotamiento, la necesidad de apoyo social puede no ser tan apremiante. Sin embargo, el aumento en la percepción de apoyo social puede indicar un posible aumento simultáneo en el nivel de burnout.

```{python}
# Plot all three heatmaps in a single row
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

for i, (time_df, time_label) in enumerate(zip([df[['autocompasion1', 'burnout1', 'apoyo_social1']],
                                               df[['autocompasion2', 'burnout2', 'apoyo_social2']],
                                               df[['autocompasion3', 'burnout3', 'apoyo_social3']]], 
                                              ['Línea Base', '3 meses', '6 meses']), 1):
    correlation_matrix = time_df.corr()
    
    # Plot a heatmap on each subplot
    sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=.5, ax=axes[i-1])
    axes[i-1].set_title(f'{time_label}')

# Adjust layout
plt.tight_layout()
plt.show()
```
Autocompasion
- Tiene una correlación positiva con el burnout. Cuando aumenta la autocompasión, el agotamiento también tiende a aumentar
- Tiene una correlación negativa con el apoyo social. Cuando la autocompasión aumenta, el apoyo social tiende a disminuir.

Burnout
- Tiene una correlación positiva con la automapasión. Cuando aumenta el agotamiento, la autocompasión también tiende a aumentar
- Tiene una correlación negativa con el apoyo social. Cuando aumenta el burnout, el apoyo social tiende a disminuir

Apoyo Social:
- Tiene una correlación negativa con la automapasión. Cuando el apoyo social disminuye, la autocompasión también tiende a disminuir
- Tiene una correlación negativa con el apoyo social. Cuando el apoyo social disminuye, el agotamiento tiende a disminuir


Cread una función que clasifique cada individuo de la muestra de acuerdo al siguiente criterio:

Si t3=t1:estable
Si t3<t1:inestable positivo (SCS y CBQ) o negativo (BPSSQ)
Si t3>t1:inestable negativo (SCS y CBQ) o positivo (BPSSQ)
Utilizad la nueva función para clasificar a los participantes en el estudio por separado por cada dimensión de interés (autocompasión, burnout y apoyo social percibido). Guardad estas clasificaciones como nuevas variables de la base de datos.

```{python}
# Función para clasificar a cada individuo
def clasificar_compasion(row):
    if row['autocompasion3'] == row['autocompasion1']:
        return 'estable'
    elif row['autocompasion3'] < row['autocompasion1']:
        return 'inestable positivo'
    else:
        return 'inestable negativo'

# Aplicar la función a la dimensión de autocompasión y crear nueva variable
df_new['clasificacion_autocompasion'] = df_new.apply(clasificar_compasion, axis=1)
```

```{python}
# Repetir el proceso para las otras dimensiones (burnout y apoyo social)
# Función para clasificar burnout
def clasificar_burnout(row):
    if row['burnout3'] == row['burnout1']:
        return 'estable'
    elif row['burnout3'] < row['burnout1']:
        return 'inestable positivo'
    else:
        return 'inestable negativo'

# Aplicar la función a la dimensión de burnout y crear nueva variable
df_new['clasificacion_burnout'] = df_new.apply(clasificar_burnout, axis=1)
```


```{python}
# Función para clasificar apoyo social
def clasificar_apoyo_social(row):
    if row['apoyo_social3'] == row['apoyo_social1']:
        return 'estable'
    elif row['apoyo_social3'] < row['apoyo_social1']:
        return 'inestable negativo'
    else:
        return 'inestable positivo'

# Aplicar la función a la dimensión de apoyo social y crear nueva variable
df_new['clasificacion_apoyo_social'] = df_new.apply(clasificar_apoyo_social, axis=1)
df_new.head()
```

¿Existe relación entre las variables categóricas creadas en el apartado anterior? Realizad todos los análisis bivariantes posibles (escogiendo 2 variables cada vez)

```{python}
df_cat = df_new[['clasificacion_autocompasion', 'clasificacion_burnout', 'clasificacion_apoyo_social']]
```

```{python}
# tabla de contingencia
cont_tbl_auto_burn = pd.crosstab(df_cat['clasificacion_autocompasion'], df_cat['clasificacion_burnout'])
cont_tbl_auto_apoy = pd.crosstab(df_cat['clasificacion_autocompasion'], df_cat['clasificacion_apoyo_social'])
cont_tbl_burn_apoy = pd.crosstab(df_cat['clasificacion_burnout'], df_cat['clasificacion_apoyo_social'])
```


```{python}
# chi-square y p-value
chi2, p, _, _ = chi2_contingency(cont_tbl_auto_burn)
# cramer's v
V_cramer = np.sqrt(chi2 / (cont_tbl_auto_burn.sum().sum() * (np.min(cont_tbl_auto_burn.shape) - 1)))

# resultados
print("Autocompasion y Burnout")
print(" ")
print(cont_tbl_auto_burn)
print(" ")
print('Chi-Square = {:.2f}'.format(chi2))
print('P-Value = {:.4f}'.format(p))      
print('Cramer\'s V = {:.2f}'.format(V_cramer))

# interpretación
if p < 0.05:
    print("\nLas variables son dependientes.")
else:
    print("\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.")
```

```{python}
# chi-square y p-value
chi2, p, _, _ = chi2_contingency(cont_tbl_auto_apoy)
# cramer's v
V_cramer = np.sqrt(chi2 / (cont_tbl_auto_apoy.sum().sum() * (np.min(cont_tbl_auto_apoy.shape) - 1)))


# resultados
print("Autocompasion y Apoyo Social")
print(" ")
print(cont_tbl_auto_apoy)
print(" ")
print('Chi-Square = {:.2f}'.format(chi2))
print('P-Value = {:.4f}'.format(p))      
print('Cramer\'s V = {:.2f}'.format(V_cramer))

# interpretación
if p < 0.05:
    print("\nLas variables son dependientes.")
else:
    print("\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.")
```

```{python}
# chi-square y p-value
chi2, p, _, _ = chi2_contingency(cont_tbl_burn_apoy)
# cramer's v
V_cramer = np.sqrt(chi2 / (cont_tbl_burn_apoy.sum().sum() * (np.min(cont_tbl_burn_apoy.shape) - 1)))

# resultados
print("\nBurnout y Apoyo Social")
print(" ")
print(cont_tbl_burn_apoy)
print(" ")
print('Chi-Square = {:.2f}'.format(chi2))
print('P-Value = {:.4f}'.format(p))      
print('Cramer\'s V = {:.2f}'.format(V_cramer))

# interpretación
if p < 0.05:
    print("\nLas variables son dependientes.")
else:
    print("\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.")
```

Como todos os P-values são > 0.05, indica que as variáveis são independentes.

Complementad los análisis bivariantes anteriores con gráficos adecuados para favorecer la inspección visual de las distribuciones conjuntas.

```{python}
# Melt the DataFrame to have a single column for variable names and values
df_melted = pd.melt(df_cat[['clasificacion_autocompasion', 'clasificacion_burnout', 'clasificacion_apoyo_social']], var_name='Variable', value_name='Category')
```


```{python}
# Get unique combinations of Variable and Category
combinations = df_melted.groupby(['Variable', 'Category']).size().reset_index(name='Count')
```

```{python}
# Create a mosaic chart
mosaic_data = pd.crosstab(df_melted['Variable'], df_melted['Category'])
mosaic_data
```


```{python}
palette_dimensions = 'Set2'
palette_status = 'Set3'

# Create subplots
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Plot the first chart on the left subplot with the specified color palette
sns.countplot(x='Variable', hue='Category', data=df_melted, ax=axes[0], palette=palette_dimensions)
axes[0].set_title('Dimensions by Status')

# Plot the second chart on the right subplot with a different color palette
sns.barplot(x='Category', y='Count', hue='Variable', data=combinations, 
            order=combinations['Category'].unique(), ax=axes[1], palette=palette_status)
axes[1].set_title('Status by Dimensions')

# Adjust layout to prevent clipping of titles and labels
plt.tight_layout()

# Show the plots
plt.show()
```