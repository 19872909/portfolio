[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "üë®üèª‚Äçüéì B.E. in Chemical Engineering |State University of Maring√° - UEM| 2016-2020.\nüèÖ Specialized in Artificial and Computational Intelligence |Federal University of Vi√ßosa - UFV| 2023-2024.\n\nüî≠ I‚Äôm currently working as a Data Scientist focusing on building predictive models for agribusiness.\nüå± I‚Äôve been directing my studies towards statistics, in order to optimize the extraction of insights from mass data.\nüí¨ We can talk about the entire development pipeline of predictive models using Python language.\nüòÑ Pronouns: He/His.\n‚ö° Curiosity: I majored in Chemical Engineering at the end of 2020. Soon after, I started my journey in the chemical industry in the R & D sector, however my passion for technology and data analysis started to speak louder (I have been using computer programming since 2016, solving engineering problems). So, I decided to enter the world of Data Science, starting in the BI/BA area and later going to work as a Data Scientist with a focus on the development and deployment of Machine Learning models."
  },
  {
    "objectID": "index.html#hello-welcome-to-my-portfolio-profile.",
    "href": "index.html#hello-welcome-to-my-portfolio-profile.",
    "title": "Home",
    "section": "",
    "text": "üë®üèª‚Äçüéì B.E. in Chemical Engineering |State University of Maring√° - UEM| 2016-2020.\nüèÖ Specialized in Artificial and Computational Intelligence |Federal University of Vi√ßosa - UFV| 2023-2024.\n\nüî≠ I‚Äôm currently working as a Data Scientist focusing on building predictive models for agribusiness.\nüå± I‚Äôve been directing my studies towards statistics, in order to optimize the extraction of insights from mass data.\nüí¨ We can talk about the entire development pipeline of predictive models using Python language.\nüòÑ Pronouns: He/His.\n‚ö° Curiosity: I majored in Chemical Engineering at the end of 2020. Soon after, I started my journey in the chemical industry in the R & D sector, however my passion for technology and data analysis started to speak louder (I have been using computer programming since 2016, solving engineering problems). So, I decided to enter the world of Data Science, starting in the BI/BA area and later going to work as a Data Scientist with a focus on the development and deployment of Machine Learning models."
  },
  {
    "objectID": "index.html#tools-and-technologies.",
    "href": "index.html#tools-and-technologies.",
    "title": "Home",
    "section": "Tools and Technologies.",
    "text": "Tools and Technologies."
  },
  {
    "objectID": "projects1.html",
    "href": "projects1.html",
    "title": "Projects1",
    "section": "",
    "text": "Introdu√ß√£o do Projeto 1\n\n\nObjetivos do Projeto 1\n\n\nResultado do Projeto 1\n\nimport pandas     as pd\nimport numpy      as np\nimport matplotlib.pyplot as plt\nimport seaborn    as sns\n\n########################## AN√ÅLISE EXPLORAT√ìRIA ###############################\n\n#%% ########################## 1. UNIVARIADA ##################################\ndf = pd.read_excel(\"Dados_EB.xls\", sheet_name = \"Tabela 2.1\")\n\n# Ajustando cabe√ßalho\ndf.columns = df.iloc[0,]\n\n# Removendo colunas desnecess√°rias\ndf = (\n      df\n      .drop(0, axis = 0)\n      .drop(['N', 'Meses'], axis = 1)\n      .reset_index(drop = True)\n      )\n\ndf.columns\n\"\"\"\nLayout de Extra√ß√£o dos Dados\n\n    1. Estado Civil         : solteiro/casado  \n    2. Grau de Instru√ß√£o    : ensino fundamental, ensino m√©dio, superior\n    3. N de Filhos          : Qtd d Filhos\n    4. Anos                 : Idade em anos\n    5. Regi√£o de Proced√™ncia: interior, capital ou outra\n    6. Salario (x Sal Min)  : Multiplo do Sal√°rio (1x, 2x)\n\n\"\"\"\n\n# Temos 36 registros\ndf.shape[0]\n\n\n# Temos 6 vari√°veis\ndf.shape[1]\n\n# ------------------------- 1. Estado Civil -----------------------------------\n\n# Qualitativa Nominal\nvar_name = \"Estado Civil\"\n\n# Sem valores nulos\ndf[var_name].isnull().sum()\ndf[var_name] = df[var_name].astype(str)\n\n# Distribui√ß√£o\n\n# freq absoulta\ncross_table = df[var_name].value_counts().to_frame(\"fa\")\n\n# freq absoulta acumulada\ncross_table[\"fa_ac\"] = cross_table[\"fa\"].cumsum()\n\n# freq relativa\ncross_table[\"fr\"] = cross_table[\"fa\"]/cross_table[\"fa\"].sum()\n\n# freq relativa acumulada\ncross_table[\"fr_ac\"] = cross_table[\"fr\"].cumsum()\ncross_table = cross_table.reset_index().rename(columns = {'index': var_name})\n\n#  Estado Civil  fa  fa_ac        fr     fr_ac\n#        casado  20     20  0.555556  0.555556\n#      solteiro  16     36  0.444444  1.000000\n\n\ndata = cross_table.reset_index()\nplt.figure(figsize=(3,3))\nsns.barplot(data=data, x=var_name, y='fr')\nplt.show()\n\n# OBS: Aproximadamente metade para cada categoria\n\n# ------------------------- 2. Grau de Instru√ß√£o ------------------------------\n\n# Qualitativa Ordinal\nvar_name = \"Grau de Instru√ß√£o\"\n\n# Sem valores nulos\ndf[var_name].isnull().sum()\ndf[var_name] = df[var_name].astype(str)\n\n# Distribui√ß√£o\n\n# freq absoulta\ncross_table = df[var_name].value_counts().to_frame(\"fa\")\n\n# freq absoulta acumulada\ncross_table[\"fa_ac\"] = cross_table[\"fa\"].cumsum()\n\n# freq relativa\ncross_table[\"fr\"] = cross_table[\"fa\"]/cross_table[\"fa\"].sum()\n\n# freq relativa acumulada\ncross_table[\"fr_ac\"] = cross_table[\"fr\"].cumsum()\ncross_table = cross_table.reset_index().rename(columns = {'index': var_name})\n\n#    Grau de Instru√ß√£o  fa  fa_ac        fr     fr_ac\n#        ensino m√©dio  18     18  0.500000  0.500000\n#  ensino fundamental  12     30  0.333333  0.833333\n#            superior   6     36  0.166667  1.000000\n\n\ndata = cross_table.reset_index()\nplt.figure(figsize=(3,3))\nsns.barplot(data=data, x=var_name, y='fr')\nplt.show()\n\n# OBS: 50% √© ensino m√©dio\n\n# ------------------------- 3. N de Filhos ------------------------------------\n\n# Quantitativa Discreta\nvar_name = \"N de Filhos\"\n\n# 16 registros nulos - 44%\ndf[var_name].isnull().sum()/df.shape[0]\n\n# OBS: Devido a elevada quantidade de informa√ß√£o ausente, iremos deprezar essa\n# vari√°vel.\ndf.drop(var_name, axis = 1, inplace = True)\n\n\n# ------------------------- 4. Anos -------------------------------------------\n\n# Quantitativa Disceta\nvar_name = \"Anos\"\n\n# Sem valores nulos\ndf[var_name].isnull().sum()/df.shape[0]\ndf[var_name] = df[var_name].astype(int)\n\n# Distribui√ß√£o\ndf[var_name].describe()\n# mean     34.583333\n# std       6.737422\n# min      20.000000\n# 25%      30.000000\n# 50%      34.500000\n# 75%      40.000000\n# max      48.000000\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\nfig.suptitle(\"An√°lise da Distribui√ß√£o\")\n\ndata = df[[var_name]]\nsns.histplot(data=data, x=var_name, stat='probability', ax=axes[0])\naxes[0].set_title(\"Histograma\")\n\nsns.boxplot(data=data, x=var_name, ax=axes[1])\naxes[1].set_title(\"Boxplot\")\n\nplt.show()\n\n# OBS: Vari√°vel com distribui√ß√£o aproximadamente sim√©trica \n# (m√©dia e mediana pr√≥ximas).\n\n# ------------------------- 5. Regi√£o de Proced√™ncia --------------------------\n\n# Qualitativa Ordinal\nvar_name = \"Regi√£o de Proced√™ncia\"\n\n# Sem valores nulos\ndf[var_name].isnull().sum()\ndf[var_name] = df[var_name].astype(str)\n\n# Distribui√ß√£o\n\n# freq absoulta\ncross_table = df[var_name].value_counts().to_frame(\"fa\")\n\n# freq absoulta acumulada\ncross_table[\"fa_ac\"] = cross_table[\"fa\"].cumsum()\n\n# freq relativa\ncross_table[\"fr\"] = cross_table[\"fa\"]/cross_table[\"fa\"].sum()\n\n# freq relativa acumulada\ncross_table[\"fr_ac\"] = cross_table[\"fr\"].cumsum()\ncross_table = cross_table.reset_index().rename(columns = {'index': var_name})\n\n#  Regi√£o de Proced√™ncia  fa  fa_ac        fr     fr_ac\n#                 outra  13     13  0.361111  0.361111\n#              interior  12     25  0.333333  0.694444\n#               capital  11     36  0.305556  1.000000\n\n\ndata = cross_table.reset_index()\nplt.figure(figsize=(3,3))\nsns.barplot(data=data, x=var_name, y='fr')\nplt.show()\n\n# OBS: Classes bem distribu√≠das, praticamente 33% em cada.\n\n\n# ------------------------- 6. Salario (x Sal Min) ----------------------------\n\n# Quantitativa Cont√≠nua\nvar_name = \"Salario (x Sal Min)\"\n\n# Sem valores nulos\ndf[var_name].isnull().sum()/df.shape[0]\ndf[var_name] = df[var_name].astype(float)\n\n# Distribui√ß√£o\ndf[var_name].describe()\n# mean     10.611111\n# std       4.574949\n# min       4.000000\n# 25%       7.000000\n# 50%       9.500000\n# 75%      13.250000\n# max      23.000000\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\nfig.suptitle(\"An√°lise da Distribui√ß√£o\")\n\ndata = df[[var_name]]\nsns.histplot(data=data, x=var_name, stat='probability', ax=axes[0])\naxes[0].set_title(\"Histograma\")\n\nsns.boxplot(data=data, x=var_name, ax=axes[1])\naxes[1].set_title(\"Boxplot\")\n\nplt.show()\n\n# OBS: Vari√°vel com distribui√ß√£o assim√©trica √† direita\n\n\n#%% ########################## 2. BIVARIADA ###################################\n\n\"\"\"\nLayout de Extra√ß√£o dos Dados\n\n    1. Estado Civil         : solteiro/casado  \n    2. Grau de Instru√ß√£o    : ensino fundamental, ensino m√©dio, superior\n    3. Anos                 : Idade em anos\n    4. Regi√£o de Proced√™ncia: interior, capital ou outra\n    5. Salario (x Sal Min)  : Multiplo do Sal√°rio (1x, 2x)\n\n    Vamos analisar as seguintes rela√ß√µes/associa√ß√µes entre:\n        \n        1. Estado Civil          x Salario (x Sal Min)   - Quali  x Quanti\n        2. Grau de Instru√ß√£o     x Salario (x Sal Min)   - Quali  x Quanti\n        3. Regi√£o de Proced√™ncia x Salario (x Sal Min)   - Quali  x Quanti\n        4. Anos                  x Salario (x Sal Min)   - Quanti x Quanti\n        5. Grau de Instru√ß√£o     x Regi√£o de Proced√™ncia - Quali  x Quali\n\n\"\"\"\n\n#------------------ 1. Estado Civil x Salario (x Sal Min) ---------------------\n\n# considerar ddof = 0 (popula√ß√£o)\n\nX = \"Estado Civil\"\nY = \"Salario (x Sal Min)\"\n \ndata = df[[X, Y]]\nglobal_variance = np.var(data[Y])\n\n\n# 1.1. Graficamente \nsns.boxplot(\n    data=data, x=X, y=Y,\n    #notch=True, showcaps=False,\n    flierprops={\"marker\": \"x\"},\n    boxprops={\"facecolor\": (.4, .6, .8, .5)},\n    medianprops={\"color\": \"coral\"},\n)\n# O Boxplot n√£o mostra uma diferen√ßa significativa entre solteiro e casado, e \n# embora haja uma leve disparidade favorecendo os casados, n√£o h√° informa√ß√£o clara\n# de que um grupo tem salario maior do que o outro. \n\n\n# 1.2. Quantitativamente\ntab = pd.merge(\n       data.groupby(X)[Y].count(),\n       data.groupby(X)[Y].apply(lambda x: np.var(x, ddof=0)),\n       how = \"left\",\n       left_index=True,\n       right_index=True,\n       validate = \"one_to_one\"\n       )\n\ntab.columns = [\"freq\", \"variance\"]\n\nmean_variance = (tab[\"freq\"] * tab[\"variance\"]).sum()/tab[\"freq\"].sum()\n\nR2 = (global_variance - mean_variance) / global_variance\n#0.06125048279545073\n# Podemos dizer que a varia√ß√£o do Estado Civil √© capaz de explicar \n# somente 6,1 % da variabilidade total do Sal√°rio, portanto parece que a \n# rela√ß√£o √© praticamente inexistente\n\n# OBS: Conclu√≠mos que parecer n√£o existir uma rela√ß√£o significativa entre as \n# vari√°veis.\n\n\n#------------------ 2. Grau de Instru√ß√£o  x Salario (x Sal Min) ---------------------\n\nX = \"Grau de Instru√ß√£o\"\nY = \"Salario (x Sal Min)\"\n \ndata = df[[X, Y]]\n\n# 1.1. Graficamente \nsns.boxplot(\n    data=data, x=X, y=Y,\n    #notch=True, showcaps=False,\n    flierprops={\"marker\": \"x\"},\n    boxprops={\"facecolor\": (.4, .6, .8, .5)},\n    medianprops={\"color\": \"coral\"},\n)\n# O Boxplot sugere que h√° uma rela√ß√£o entre Grau de Instru√ß√£o com sal√°rio. \n# De acordo com o gr√°fico, quanto maior o grau de instru√ß√£o, maior\n# o sal√°rio\n\n\n# 1.2. Quantitativamente\ntab = pd.merge(\n       data.groupby(X)[Y].count(),\n       data.groupby(X)[Y].apply(lambda x: np.var(x, ddof=0)),\n       how = \"left\",\n       left_index=True,\n       right_index=True,\n       validate = \"one_to_one\"\n       )\n\ntab.columns = [\"freq\", \"variance\"]\n\nmean_variance = (tab[\"freq\"] * tab[\"variance\"]).sum()/tab[\"freq\"].sum()\n\nR2 = (global_variance - mean_variance) / global_variance\n# 0.41329658948948933\n# Podemos dizer que a varia√ß√£o do Grau de Instru√ß√£o √© capaz de explicar \n# 41,3% da variabilidade total do Sal√°rio, portanto parece que h√° uma rela√ß√£o \n# significativa entre as vari√°veis\n\n# OBS: Conclu√≠mos que parece existir uma rela√ß√£o significativa entre as vari√°veis.\n\n\n#------------------ 3. Regi√£o de Proced√™ncia x Salario (x Sal Min) ------------\n\nX = \"Regi√£o de Proced√™ncia\"\nY = \"Salario (x Sal Min)\"\n \ndata = df[[X, Y]]\n\n# 1.1. Graficamente \nsns.boxplot(\n    data=data, x=X, y=Y,\n    #notch=True, showcaps=False,\n    flierprops={\"marker\": \"x\"},\n    boxprops={\"facecolor\": (.4, .6, .8, .5)},\n    medianprops={\"color\": \"coral\"},\n)\n# O Boxplot sugere que n√£o h√° uma rela√ß√£o entre Regi√£o de Proced√™ncia com sal√°rio. \n\n\n# 1.2. Quantitativamente\ntab = pd.merge(\n       data.groupby(X)[Y].count(),\n       data.groupby(X)[Y].apply(lambda x: np.var(x, ddof=0)),\n       how = \"left\",\n       left_index=True,\n       right_index=True,\n       validate = \"one_to_one\"\n       )\n\ntab.columns = [\"freq\", \"variance\"]\n\nmean_variance = (tab[\"freq\"] * tab[\"variance\"]).sum()/tab[\"freq\"].sum()\n\nR2 = (global_variance - mean_variance) / global_variance\n# 0.012725018471166834\n# Podemos dizer que a varia√ß√£o do Grau de Instru√ß√£o √© capaz de explicar \n# 1,3% da variabilidade total do Sal√°rio, portanto parece que h√° uma rela√ß√£o \n# significativa entre as vari√°veis\n\n# OBS: Conclu√≠mos que parece n√£o existir uma rela√ß√£o significativa entre as vari√°veis.\n\n\n#------------------ 4. Anos x Salario (x Sal Min) - Quanti x Quanti -----------\n\nX = \"Anos\"\nY = \"Salario (x Sal Min)\"\n \ndata = df[[X, Y]]\n\n# 1.1. Graficamente \nsns.scatterplot(data=data, x=X, y=Y)\n\n# O gr√°fico de dispers√£o sugere que h√° uma certa rela√ß√£o entre idade e sal√°rio. \n\n\n# 1.2. Quantitativamente\nstd_X  = np.std(data[X])\nstd_Y  = np.std(data[Y])\nmean_X = np.mean(data[X])\nmean_Y = np.mean(data[Y])\nn      = data.shape[0]\ncov_XY = np.sum((data[X] - mean_X)*(data[Y] - mean_Y))/n\nR      = corr_XY = cov_XY/(std_X * std_Y)\n#0.363362180908158\n# Dessa forma vemos que existe uma correla√ß√£o linear direta de for√ßa fraca\n# entre a idade em anos e o sal√°rio.\n\n\n# -------- 5. Grau de Instru√ß√£o x Regi√£o de Proced√™ncia - Quali x Quali -------\nX = \"Regi√£o de Proced√™ncia\"\nY = \"Grau de Instru√ß√£o\"\n \ndata = df[[X, Y]]\n\n# Freq. observadas\nobs_abs = pd.crosstab(data[X], data[Y], margins=True)\nobs_abs \n# Grau de Instru√ß√£o      ensino fundamental  ensino m√©dio  superior  All\n# Regi√£o de Proced√™ncia                                                 \n# capital                                 4             5         2   11\n# interior                                3             7         2   12\n# outra                                   5             6         2   13\n# All                                    12            18         6   36\n\n# Aqui temos os valores observados relativos referentes as linhas (soma da linha \n# da 100%)\nobs = pd.crosstab(data[X], data[Y], normalize='index', margins=True)\nobs\n# Grau de Instru√ß√£o      ensino fundamental  ensino m√©dio  superior\n# Regi√£o de Proced√™ncia                                            \n# capital                          0.363636      0.454545  0.181818\n# interior                         0.250000      0.583333  0.166667\n# outra                            0.384615      0.461538  0.153846\n# All                              0.333333      0.500000  0.166667\n\n# Supondo que n√£o haja associa√ß√£o entre X e Y, ou seja, esperamos que independente \n# de ser capital, interior ou outra, que tenhamos sempre a mesma distribui√ß√£o do Grau de \n# Instru√ß√£o e que essa seja igual a vista em All:\nexp = np.matmul(\n    obs_abs.loc[:,\"All\"].drop(\"All\").values.reshape(-1, 1),\n    obs.loc[\"All\"].values.reshape(1, -1)\n    )\n\n#array([[3.66666667, 5.5       , 1.83333333],\n#       [4.        , 6.        , 2.        ],\n#       [4.33333333, 6.5       , 2.16666667]])\n\nobs_abs = obs_abs.drop(\"All\", axis = 0).drop(\"All\", axis = 1)\nX2      = (((obs_abs - exp)**2)/exp).sum().sum()\nr       = obs_abs.shape[0]\nc       = obs_abs.shape[1]\nq       = np.min([c,r])\nn       = obs_abs.sum().sum()\nV       = np.sqrt(X2/(n*(q-1)))\n# 0.09584578987318869\n# Portanto a associa√ß√£o entre X e Y parece ser baixa, uma vez que o Coeficiente\n# V de Cramer ficou muito pr√≥ximo de 0.\n\n# Todo o calculo acima poderia ser feito de forma resumida automatica\n# com o scipy:\n# from scipy import stats as st\n# st.contingency.association(obs_abs)\n# 0.09584578987318869\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprint(\"Hello World\")\n\nHello World"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "In progress"
  },
  {
    "objectID": "projects2.html",
    "href": "projects2.html",
    "title": "Projects2",
    "section": "",
    "text": "Introdu√ß√£o do Projeto 2\n\n\nObjetivos do Projeto 2\n\n\nResultado do Projeto 2"
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "Reference",
    "section": "",
    "text": "Livro 1\n\n\nLivro 2\n\n\nLivro 3"
  }
]