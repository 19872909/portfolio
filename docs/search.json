[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "I have over five years of experience in Business Intelligence and Data Science, having collaborated with international corporations such as Samsung, InBev, Bayer, and Honda across various business domains including marketing, operations management, and customer experience.\nAs a Data Scientist, I have worked within cross-functional teams to deliver data-driven solutions, establish data governance frameworks, and utilize advanced analytics to extract insights.\nI am studying Behavioral Data Science at the Universitat de Barcelona. This program is enhancing my skills in data analysis, statistical modeling, machine learning, deep learning, and data visualization using R and Python. It also gives me an understanding of psychology and behavioral economics, focusing on psychographics, predictive behavioral modeling, and psychometrics. This educational experience is enabling me to apply data science in ways that are more empathetic and impactful.\n\nBS in Electrical Engineering-Telecommunication - PUC Campinas, SP - 2011\nSpecialization in Complex Data Mining - Unicamp, SP - 2018\nSpecialization in Computer Software Engineering - Unicamp, SP - 2013\nSpecialization in Data Science (Big Data Processing and Analytics) - Mackenzie, SP - 2021\nMaster Behavioral Data Science - Barcelona University - 2024"
  },
  {
    "objectID": "index.html#my-portfolio",
    "href": "index.html#my-portfolio",
    "title": "Home",
    "section": "",
    "text": "I have over five years of experience in Business Intelligence and Data Science, having collaborated with international corporations such as Samsung, InBev, Bayer, and Honda across various business domains including marketing, operations management, and customer experience.\nAs a Data Scientist, I have worked within cross-functional teams to deliver data-driven solutions, establish data governance frameworks, and utilize advanced analytics to extract insights.\nI am studying Behavioral Data Science at the Universitat de Barcelona. This program is enhancing my skills in data analysis, statistical modeling, machine learning, deep learning, and data visualization using R and Python. It also gives me an understanding of psychology and behavioral economics, focusing on psychographics, predictive behavioral modeling, and psychometrics. This educational experience is enabling me to apply data science in ways that are more empathetic and impactful.\n\nBS in Electrical Engineering-Telecommunication - PUC Campinas, SP - 2011\nSpecialization in Complex Data Mining - Unicamp, SP - 2018\nSpecialization in Computer Software Engineering - Unicamp, SP - 2013\nSpecialization in Data Science (Big Data Processing and Analytics) - Mackenzie, SP - 2021\nMaster Behavioral Data Science - Barcelona University - 2024"
  },
  {
    "objectID": "index.html#tools",
    "href": "index.html#tools",
    "title": "Home",
    "section": "Tools",
    "text": "Tools"
  },
  {
    "objectID": "project1.html",
    "href": "project1.html",
    "title": "1. Classification Dimensions Analysis",
    "section": "",
    "text": "This report presents a classification of students based on the dimensions of self-compassion, burnout, and perceived social support.\n\nimport openpyxl\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2_contingency\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n\ndf = pd.read_excel('./source/DATA_Coaches.xlsx',engine='openpyxl')\n\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nt1scs1\nt1scs2\nt1scs3\nt1scs4\nt1scs5\nt1scs6\nt1scs7\nt1scs8\nt1scs9\nt1scs10\n...\nt3cbq12\nt3cbq13\nt3cbq14\nt3cbq15\nt3ssq1\nt3ssq2\nt3ssq3\nt3ssq4\nt3ssq5\nt3ssq6\n\n\n\n\ncount\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n...\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n\n\nmean\n8.099526\n8.201422\n8.860190\n8.855450\n7.950237\n7.744076\n8.644550\n8.180095\n8.225118\n7.412322\n...\n387.127962\n386.914692\n382.395735\n386.864929\n388.277251\n388.606635\n388.478673\n388.457346\n388.483412\n388.464455\n\n\nstd\n67.638234\n68.458283\n68.410955\n67.585122\n68.479342\n68.492494\n68.426785\n67.634590\n67.630153\n68.516764\n...\n485.981977\n486.151265\n480.209295\n486.190762\n485.069049\n484.807454\n484.909119\n484.926090\n484.905504\n484.920634\n\n\nmin\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n25%\n3.000000\n3.000000\n4.000000\n4.000000\n2.000000\n2.000000\n4.000000\n3.000000\n3.000000\n2.000000\n...\n2.000000\n1.000000\n2.000000\n1.000000\n4.000000\n5.000000\n4.000000\n4.000000\n4.000000\n4.000000\n\n\n50%\n3.000000\n4.000000\n4.000000\n4.000000\n3.000000\n3.000000\n4.000000\n4.000000\n4.000000\n3.000000\n...\n3.000000\n2.000000\n2.000000\n2.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n\n\n75%\n4.000000\n4.000000\n5.000000\n5.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n...\n999.000000\n999.000000\n987.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n\n\nmax\n987.000000\n999.000000\n999.000000\n987.000000\n999.000000\n999.000000\n999.000000\n987.000000\n987.000000\n999.000000\n...\n999.000000\n999.000000\n987.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n\n\n\n\n8 rows × 99 columns",
    "crumbs": [
      "Projects",
      "1. Classification Dimensions Analysis"
    ]
  },
  {
    "objectID": "project1.html#correlations",
    "href": "project1.html#correlations",
    "title": "Project: PIMA Indians Diabetes",
    "section": "Correlations",
    "text": "Correlations\n\nEach square shows the correlation between the variables on each axis. Correlation ranges from -1 to +1.\n\nValues closer to 0: There is no linear trend between the two variables.\nValues closer to 1: The correlation is positive; that is as one increases so does the other and the closer to 1 the stronger this relationship is.\nValues closer to -1: One variable will decrease as the other increases\n\nThe diagonals are all 1/dark because those squares are correlating each variable to itself (so it’s a perfect correlation). For the rest the larger the number and darker the color the higher the correlation between the two variables.\n\n\n\nCorrelation matrix:\nThere is a strong positve correlation between Pregnancies and Age, Glucose and Outcome. There is a strong negative correlation between Skinthickness and Age, Pregnancies and SkinThickness, Pregnance and Insulin\n\n#Correlation of features with the Outcome\ncorr_report = pima.corr()['Outcome']\ncorr_report.sort_values(ascending=False)\n\nOutcome                     1.000000\nGlucose                     0.466581\nBMI                         0.292695\nAge                         0.238356\nPregnancies                 0.221898\nDiabetesPedigreeFunction    0.173844\nInsulin                     0.130548\nSkinThickness               0.074752\nBloodPressure               0.065068\nName: Outcome, dtype: float64\n\n\n\noutliers = pima[pima['Glucose'] &gt; 150]\noutliers\n\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n8\n2\n197\n70\n45\n543\n30.5\n0.158\n53\n1\n\n\n11\n10\n168\n74\n0\n0\n38.0\n0.537\n34\n1\n\n\n13\n1\n189\n60\n23\n846\n30.1\n0.398\n59\n1\n\n\n14\n5\n166\n72\n19\n175\n25.8\n0.587\n51\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n749\n6\n162\n62\n0\n0\n24.3\n0.178\n50\n1\n\n\n753\n0\n181\n88\n44\n510\n43.3\n0.222\n26\n1\n\n\n754\n8\n154\n78\n32\n0\n32.4\n0.443\n45\n1\n\n\n759\n6\n190\n92\n0\n0\n35.5\n0.278\n66\n1\n\n\n761\n9\n170\n74\n31\n0\n44.0\n0.403\n43\n1\n\n\n\n\n140 rows × 9 columns\n\n\n\n\n\noutliers['Outcome'].value_counts()\n\nOutcome\n1    105\n0     35\nName: count, dtype: int64\n\n\n\n# Histogram to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.histplot(value, ax=ax[index], kde=True, stat=\"density\", linewidth=0)\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.8, w_pad=0.5, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n# Boxplot to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.boxplot(value, ax=ax[index])\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n\n\nOutliers\nThere are some outliers analyzed through the distribution of data in the histograms and boxplots.\nThey following code has removed the outliers before to proceed with the ML model.\n\nIQR - Interquartile Range\nThe lower quartile corresponds with the 25th percentile and the upper quartile corresponds with the 75th percentile, so IQR = Q3 − Q1.\nThe IQR is an example of a trimmed estimator, defined as the 25% trimmed range, which enhances the accuracy of dataset statistics by dropping lower contribution, outlying points.\n\nQ1 = pima.quantile(0.25)\nQ3 = pima.quantile(0.75)\n\n\nIQR = Q3 - Q1\nIQR\n\nPregnancies                   5.0000\nGlucose                      41.2500\nBloodPressure                18.0000\nSkinThickness                32.0000\nInsulin                     127.2500\nBMI                           9.3000\nDiabetesPedigreeFunction      0.3825\nAge                          17.0000\nOutcome                       1.0000\ndtype: float64\n\n\n\npima.shape\n\n(768, 9)\n\n\n\nThe interquartile range is often used to find outliers in data. Outliers here are defined as observations that fall below Q1 − 1.5 IQR or above Q3 + 1.5 IQR. In a boxplot, the highest and lowest occurring value within this limit are indicated by whiskers of the box (frequently with an additional bar at the end of the whisker) and any outliers as individual points.\n\n\n# Outlier removal\npima = pima[~((pima &lt; (Q1 - 1.5 * IQR)) | (pima &gt; (Q3 + 1.5 * IQR))).any(axis = 1)]\npima.shape\n\n(639, 9)\n\n\n\ncount = pima[\"Outcome\"].value_counts()\ncount\n\nOutcome\n0    439\n1    200\nName: count, dtype: int64\n\n\n\n# Data distribution\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.boxplot(value, ax=ax[index])\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n# Histogram to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.histplot(value, ax=ax[index], kde=True, stat=\"density\", linewidth=0)\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.8, w_pad=0.5, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression ML Model\n\n# Define x and y\nfeature_cols =['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\nx=pima[feature_cols]\ny=pima.Outcome\n\n\n#split x and y into training (70%) and testing (30%) sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=0)\n\n\n\n\nStandardize features\nStandardize features by removing the mean and scaling to unit variance.\nThe standard score of a sample x is calculated as: z = (x - u) / s, where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n\nscale = StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.fit_transform(x_test)\n\n\n#Logistic regression model fit on the training set\nlogreg = LogisticRegression(solver='lbfgs', max_iter=3000)\nlogreg.fit(x_train, y_train)\n\nLogisticRegression(max_iter=3000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=3000)\n\n\n\n#Using the trained model to predict the outcome for samples in x_test.\ny_pred = logreg.predict(x_test)\n\n\n#Return the probability estimates.\ny_score = logreg.predict_proba(x_test)[:, 1]\n\n\n\n\nML Model Assessment\n\nPrecision: Percentage of correct positive predictions relative to total positive predictions.\nRecall: Percentage of correct positive predictions relative to total actual positives.\nF1 Score: A weighted harmonic mean of precision and recall. The closer to 1, the better the model. F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n\n\n#Comparing actual result and predicted result\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.78      0.93      0.85       127\n           1       0.78      0.48      0.59        65\n\n    accuracy                           0.78       192\n   macro avg       0.78      0.70      0.72       192\nweighted avg       0.78      0.78      0.76       192\n\n\n\n\nPrecision: Out of all the patients that the model predicted would get diabetes, 78% actually did.\nRecall: Out of all the patients that actually did get diabetes, the model predicted this outcome correctly for 48% of those patients.\nF1 Score: 0.59 - Since this value is close to 1, it tells us that the model does a good job of predicting whether or not patients will get diabetes. 2 * (Precision * Recall) / (Precision + Recall) ***** 2 * (.78 * .48) / (.78 + .48)\nSupport: These values is regarding how many patients belonged to each class in the test dataset. Among the patientis in the test dataset, 127 did not get diabetes and 65 did get diabetes.\n\n\n#The lower the RMS value, the better. O means the model is perfect.\nrms = mean_squared_error(y_test, y_pred, squared=False)\nrms\n\n0.4732423621500228\n\n\n\n\n\nROC Curve\nThe ROC curve shows the trade-off between sensitivity (or True Positve Rate) and specificity (1 – False Positive Rate).\nClassifiers that give curves closer to the top-left corner indicate a better performance\nROC/AUC does not require to set a classification threshold and it’s still useful when there is high class imbalance\n\nROC curve can help you to choose a threshold that balances sensitivity and specificity in a way that makes sense for your particular context\nYou can’t actually see the thresholds used to generate the curve on the ROC curve itself\n\n\nfpr, tpr, thresh = roc_curve(y_test, y_score, pos_label=logreg.classes_[1])\n\n\n#AUC is the percentage of the ROC plot that is underneath the curve:\n# IMPORTANT: first argument is true values, second argument is predicted probabilities\nprint(metrics.roc_auc_score(y_test, y_pred))\n\n0.7030284675953968\n\n\n\nplt.figure(figsize=(6,4))\nplt.plot(fpr, tpr, linewidth=1, marker='.', label='Logistic')\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.rcParams['font.size'] = 8\nplt.title('ROC curve')\nplt.xlabel('Specificity (FPR)')\nplt.ylabel('Sensitivity (TPR)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAccuracy\nPercentage of correct predictions\n\nprint('Accuracy of Logistic regression model is {}'.format(accuracy_score(y_test,y_pred)))\n\nAccuracy of Logistic regression model is 0.7760416666666666\n\n\n\n\nNull accuracy\nNull accuracy refers to the accuracy that could be achieved by always predicting the most frequent class in the dataset.\nIn the test set, 66% (127) of patients did not have diabetes, while 34% did. In this case, the null accuracy would be 66%, because if we always predicted “not diabetes,” we would be correct 66% of the time.\n\ny_test.value_counts().head(1) / len(y_test)\n\nOutcome\n0    0.661458\nName: count, dtype: float64\n\n\nAs the null accuracy is less than model accuracy, it indicates a good result.\n\nComparing the true and predicted response values\n\n#print the 25 first true and predict responses\nprint ('True:'), y_test.values[0:25]\n\nTrue:\n\n\n(None,\n array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n        0, 0, 0]))\n\n\n\nprint ('Pred:'), y_pred[0:25]\n\nPred:\n\n\n(None,\n array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n        0, 0, 1]))\n\n\n\n\n\nConfusion Matrix\nConfusion matrix allows to calculate a variety of metrics. It’s a useful for multi-class problems (more than two response classes)\n\nEvery observation in the testing set is represented in exactly one box\nIt’s 2x2 matrix because there are 2 responses classes\nThe format shown here is not universal\n\nBasic Terminology\n\nTP: correctly predict that they have diabetes\nTN: correctly predict that they do not have diabetes\nFP: incorrectly predict that they do have diabetes\nFN: incorrectly predict that they do not have diabetes\n\n\n#IMPORTANT: First argument is true values, second argument is predict values\nmetrics.confusion_matrix(y_test, y_pred)\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n#Graphic visualization\ncm = confusion_matrix(y_test, y_pred, labels=logreg.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\ndisp.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nTN: 118 patients without diabetes were correctly predicted as no diabetics\nFP: 9 patients without diabetes were incorrectly predicted as diabetics\nFN: 34 patients with diabetes were incorrectly predicted as no diabetics\nTP: 31 patients with diabetes were correctly predicted as diabetics\n\n\n#save confusion matrix and slice into four pieces\nconfusion = metrics.confusion_matrix(y_test, y_pred)\nTN = confusion[0,0]\nFP = confusion[0,1]\nFN = confusion[1,0]\nTP = confusion[1,1]\nconfusion\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\nMetrics computed from a confusion matrix\n\n#How often the classifier is correct?\nprint('Accuracy: {}'.format((TP + TN) / (TP + TN + FP + FN)))\n#print('Accuracy: {}'.format(metrics.accuracy_score(y_test, y_pred_class)))\n\nAccuracy: 0.7760416666666666\n\n\n\n\nk-Fold Cross-Validation\nThe k-fold cross-validation procedure divides a limited dataset into k non-overlapping folds. Each of the k folds is given an opportunity to be used as a held back test set, whilst all other folds collectively are used as a training dataset. A total of k models are fit and evaluated on the k hold-out test sets and the mean performance is reported.\n\n#This will give the overall accuracy of your model .\nkf = KFold(n_splits=10, random_state=1, shuffle=True)\ncv_result = cross_val_score(logreg, x, y, cv=kf, scoring='accuracy', n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(cv_result), std(cv_result)))\n\nAccuracy: 0.784 (0.033)\n\n\n\n#How often the classifier is incorrect?\nprint('Error: {}'.format((FP + FN)/(TP + TN + FP + FN)))\n#print('Error: {}'.format(1-metrics.accuracy_score(y_test, y_pred_class)))\n\nError: 0.22395833333333334\n\n\n\n#When the actual value is positive, how often is the prediction correct?\nprint('Sensitivity (TPR): {}'.format(TP / (TP + FN)))\n#metrics.recall_score(y_test, y_pred_class)\n\nSensitivity (TPR): 0.47692307692307695\n\n\n\n#When the actual value is negative, how often is the prediction correct?\nprint('Specificity (FPR): {}'.format(TN / (TN + FP))) \n#recall_score(y_test, y_pred_class, pos_label=0)\n\nSpecificity (FPR): 0.9291338582677166\n\n\n\n#When a positive value is predicted, how often is the prediction correct?\nprint('Precision: {}'.format(TP / (TP + FP))) \n#metrics.precision_score(y_test, y_pred_class)\n\nPrecision: 0.775\n\n\n\n\n\nResult\nThe choice of metrics depends on the business objective.\nFor this project, sensibility (False Negative) is the metric most important, since predicting diabetics as no diabetics is the worst expected error. This may imply no further investigations and consequently no treatment of the disease.\nSo the better result is to have a Sensitivity (The correct prediction for positive values) result higher than a Specificity (The correct prediction for negative values) result.\nThe error in predicting a healthy patient as a diabetic patient is more acceptable than the opposite.\n\n\nAdjusting the classification threshold\n\n#print the first 10 predicted responses\nlogreg.predict(x_test)[0:10]\n\narray([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n\n\n\n#print the first 10 predicted probabilities of class membership\nlogreg.predict_proba(x_test)[0:10, :]\n\narray([[0.83358342, 0.16641658],\n       [0.80138151, 0.19861849],\n       [0.95231282, 0.04768718],\n       [0.87348851, 0.12651149],\n       [0.67158939, 0.32841061],\n       [0.38292382, 0.61707618],\n       [0.93226643, 0.06773357],\n       [0.5219636 , 0.4780364 ],\n       [0.92950252, 0.07049748],\n       [0.69118097, 0.30881903]])\n\n\n\n#print the first 10 predicted probabilities for class 1\nlogreg.predict_proba(x_test)[0:10, 1]\n\narray([0.16641658, 0.19861849, 0.04768718, 0.12651149, 0.32841061,\n       0.61707618, 0.06773357, 0.4780364 , 0.07049748, 0.30881903])\n\n\n\nfig = sns.histplot(data=y_score, bins=8)\nplt.xlabel(\"Predicted probability of diabetes\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of predicted probabilities\") \nplt.xlim(0,1)\nplt.rcParams['font.size']=10\nplt.show(fig)\n\n\n\n\n\n\n\n\n\nFinding the best threshold for predicting diabetes and to increase the sensitivity of the classifier\nThreshold of 0.5 is used by default (for binary problems) to convert predicted possibilities into class predictions Threshold can be adjusted to increase sensitivity or specificity Sensitivity and specificity have an inverse relationship\n\n# calculate roc curves\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\n\n\n# calculate the g-mean for each threshold\ngmeans = sqrt(tpr * (1-fpr))\n# locate the index of the largest g-mean\nix = argmax(gmeans)\nprint('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n\nBest Threshold=0.242365, G-Mean=0.796\n\n\n\n# get the best threshold\nJ = tpr - fpr\nix = argmax(J)\nbest_thresh = thresholds[ix]\nprint('Best Threshold=%f' % (best_thresh))\n\nBest Threshold=0.242365\n\n\n\n# define a function that accepts a threshold and prints sensitivity and specificity\ndef evaluate_threshold(threshold):\n    print('Sensitivity:', tpr[thresholds &gt; threshold][-1])\n    print('Specificity:', 1 - fpr[thresholds &gt; threshold][-1])\n\n\nevaluate_threshold(0.5)\n\nSensitivity: 0.47692307692307695\nSpecificity: 0.9291338582677166\n\n\n\nevaluate_threshold(0.3)\n\nSensitivity: 0.7230769230769231\nSpecificity: 0.7795275590551181\n\n\n\nevaluate_threshold(0.242365)\n\nSensitivity: 0.8461538461538461\nSpecificity: 0.7480314960629921\n\n\n\n#predict diabetes if the predicted probabilities is greater than 0.242365\ny_pred_2 = preprocessing.binarize([y_score], threshold=0.242365)[0]\n\n\n#print the first 10 predicted probabilites\ny_pred[0:10]\n\narray([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n\n\n\n#print the first 10 predicted classes with the lower threshold\ny_pred_2[0:10]\n\narray([0., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n\n\n\n#previous confusion matrix (default threshold of 0.5)\nconfusion\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n#now confusion matrix (threshold of 0.3)\nconfusion_2 = metrics.confusion_matrix(y_test, y_pred_2)\nTN = confusion_2[0,0]\nFP = confusion_2[0,1]\nFN = confusion_2[1,0]\nTP = confusion_2[1,1]\n\n\nconfusion_2\n\narray([[95, 32],\n       [10, 55]])\n\n\n\n#sensitivity has increased (used to be 0.7384615384615385)\nprint('Sensitivity (TPR): {}'.format(TP / (TP + FN)))\n\nSensitivity (TPR): 0.8461538461538461\n\n\n\n#sensitivity has increased (used to be 0.7795275590551181)\nprint('Specificity (FPR): {}'.format(TN / (TN + FP))) \n\nSpecificity (FPR): 0.7480314960629921\n\n\n\n#AUC is the percentage of the ROC plot that is underneath the curve:\nprint(metrics.roc_auc_score(y_test, y_pred_2))\n\n0.7970926711084192\n\n\n\n\n\nConclusion\nWith a threshold of 0.242365, the sensitivity has increased from 0.48 to 0.85, and the specificity has decreased from 0.93 to 0.75. Despite the decrease in specificity, for this project, the most important metric is sensitivity, once we want to correctly predict the patients with diabetes, the correct prediction for positive values.\nThe AUC has also increased after threshold adjustment, from 0.70 to 0.79.",
    "crumbs": [
      "Projects",
      "Project: PIMA Indians Diabetes"
    ]
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "Reference",
    "section": "",
    "text": "Livro 1\n\n\nLivro 2\n\n\nLivro 3"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Welcome to the projects section of my portfolio, where I am pleased to share with you a selection of work that I have undertaken during my academic journey in the field of data science.\nThis page is an invitation for you to dive into the projects that not only demonstrate my technical competence but also my passion for transforming data into meaningful insights and practical solutions.\nShould any project capture your interest or if any questions arise, I encourage you to contact me. I am always available to exchange ideas, explore opportunities for collaboration, or simply to discuss the challenges and beauties found in the realm of data science.\nThank you for visiting, and I hope you find inspiration and valuable information here.",
    "crumbs": [
      "Projects"
    ]
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "2. Prediction of Diabetes",
    "section": "",
    "text": "PIMA Indian Diabetes dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases.\n\n\n\n\nThe objective is to predict based on diagnostic measurements whether a patient has diabetes.\n\n\n\n\n\nSeveral constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n\n\n\n\nPregnancies: Number of times pregnant\n\n\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\n\nBloodPressure: Diastolic blood pressure (mm Hg)\n\n\nSkinThickness: Triceps skin fold thickness (mm)\n\n\nInsulin: 2-Hour serum insulin (mu U/ml)\n\n\nBMI: Body mass index (weight in kg/(height in m)^2)\n\n\nDiabetesPedigreeFunction: Diabetes pedigree function\n\n\nAge: Age (years)\n\n\nOutcome: Class variable (0 or 1) 1: Diabetic, 0: Healty\n\n\n\n\n\n#%% Setup\n#Libraries import\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom numpy import sqrt\nfrom numpy import argmax\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, mean_squared_error, roc_curve, RocCurveDisplay, recall_score\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.linear_model import LogisticRegression\n\n#Dataset read\npima = pd.read_csv('./source/diabetes.csv')\n\n#The dataset has 768 rows and 9 columns\npima.shape\npima.head()\n\n\n#This output shows that all dataset features are numeric.\npima.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n\n\n\n#This function show the main statistics for the features. \npima.describe().T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nPregnancies\n768.0\n3.845052\n3.369578\n0.000\n1.00000\n3.0000\n6.00000\n17.00\n\n\nGlucose\n768.0\n120.894531\n31.972618\n0.000\n99.00000\n117.0000\n140.25000\n199.00\n\n\nBloodPressure\n768.0\n69.105469\n19.355807\n0.000\n62.00000\n72.0000\n80.00000\n122.00\n\n\nSkinThickness\n768.0\n20.536458\n15.952218\n0.000\n0.00000\n23.0000\n32.00000\n99.00\n\n\nInsulin\n768.0\n79.799479\n115.244002\n0.000\n0.00000\n30.5000\n127.25000\n846.00\n\n\nBMI\n768.0\n31.992578\n7.884160\n0.000\n27.30000\n32.0000\n36.60000\n67.10\n\n\nDiabetesPedigreeFunction\n768.0\n0.471876\n0.331329\n0.078\n0.24375\n0.3725\n0.62625\n2.42\n\n\nAge\n768.0\n33.240885\n11.760232\n21.000\n24.00000\n29.0000\n41.00000\n81.00\n\n\nOutcome\n768.0\n0.348958\n0.476951\n0.000\n0.00000\n0.0000\n1.00000\n1.00\n\n\n\n\n\n\n\n\n\n#This function shows that any of the features has null values\npima.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\n\n\n\nEach square shows the correlation between the variables on each axis. Correlation ranges from -1 to +1.\n\nValues closer to 0: There is no linear trend between the two variables.\nValues closer to 1: The correlation is positive; that is as one increases so does the other and the closer to 1 the stronger this relationship is.\nValues closer to -1: One variable will decrease as the other increases\n\nThe diagonals are all 1/dark because those squares are correlating each variable to itself (so it’s a perfect correlation). For the rest the larger the number and darker the color the higher the correlation between the two variables.\n\n\n\n\nThere is a strong positve correlation between Pregnancies and Age, Glucose and Outcome. There is a strong negative correlation between Skinthickness and Age, Pregnancies and SkinThickness, Pregnance and Insulin\n\n#Correlation of features with the Outcome\ncorr_report = pima.corr()['Outcome']\ncorr_report.sort_values(ascending=False)\n\nOutcome                     1.000000\nGlucose                     0.466581\nBMI                         0.292695\nAge                         0.238356\nPregnancies                 0.221898\nDiabetesPedigreeFunction    0.173844\nInsulin                     0.130548\nSkinThickness               0.074752\nBloodPressure               0.065068\nName: Outcome, dtype: float64\n\n\n\noutliers = pima[pima['Glucose'] &gt; 150]\noutliers\n\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n8\n2\n197\n70\n45\n543\n30.5\n0.158\n53\n1\n\n\n11\n10\n168\n74\n0\n0\n38.0\n0.537\n34\n1\n\n\n13\n1\n189\n60\n23\n846\n30.1\n0.398\n59\n1\n\n\n14\n5\n166\n72\n19\n175\n25.8\n0.587\n51\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n749\n6\n162\n62\n0\n0\n24.3\n0.178\n50\n1\n\n\n753\n0\n181\n88\n44\n510\n43.3\n0.222\n26\n1\n\n\n754\n8\n154\n78\n32\n0\n32.4\n0.443\n45\n1\n\n\n759\n6\n190\n92\n0\n0\n35.5\n0.278\n66\n1\n\n\n761\n9\n170\n74\n31\n0\n44.0\n0.403\n43\n1\n\n\n\n\n140 rows × 9 columns\n\n\n\n\n\noutliers['Outcome'].value_counts()\n\nOutcome\n1    105\n0     35\nName: count, dtype: int64\n\n\n\n# Histogram to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.histplot(value, ax=ax[index], kde=True, stat=\"density\", linewidth=0)\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.8, w_pad=0.5, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n# Boxplot to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.boxplot(value, ax=ax[index])\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n\n\n\nThere are some outliers analyzed through the distribution of data in the histograms and boxplots.\nThey following code has removed the outliers before to proceed with the ML model.\n\n\nThe lower quartile corresponds with the 25th percentile and the upper quartile corresponds with the 75th percentile, so IQR = Q3 − Q1.\nThe IQR is an example of a trimmed estimator, defined as the 25% trimmed range, which enhances the accuracy of dataset statistics by dropping lower contribution, outlying points.\n\nQ1 = pima.quantile(0.25)\nQ3 = pima.quantile(0.75)\n\n\nIQR = Q3 - Q1\nIQR\n\nPregnancies                   5.0000\nGlucose                      41.2500\nBloodPressure                18.0000\nSkinThickness                32.0000\nInsulin                     127.2500\nBMI                           9.3000\nDiabetesPedigreeFunction      0.3825\nAge                          17.0000\nOutcome                       1.0000\ndtype: float64\n\n\n\npima.shape\n\n(768, 9)\n\n\n\nThe interquartile range is often used to find outliers in data. Outliers here are defined as observations that fall below Q1 − 1.5 IQR or above Q3 + 1.5 IQR. In a boxplot, the highest and lowest occurring value within this limit are indicated by whiskers of the box (frequently with an additional bar at the end of the whisker) and any outliers as individual points.\n\n\n# Outlier removal\npima = pima[~((pima &lt; (Q1 - 1.5 * IQR)) | (pima &gt; (Q3 + 1.5 * IQR))).any(axis = 1)]\npima.shape\n\n(639, 9)\n\n\n\ncount = pima[\"Outcome\"].value_counts()\ncount\n\nOutcome\n0    439\n1    200\nName: count, dtype: int64\n\n\n\n# Data distribution\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.boxplot(value, ax=ax[index])\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n# Histogram to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.histplot(value, ax=ax[index], kde=True, stat=\"density\", linewidth=0)\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.8, w_pad=0.5, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Define x and y\nfeature_cols =['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\nx=pima[feature_cols]\ny=pima.Outcome\n\n\n#split x and y into training (70%) and testing (30%) sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=0)\n\n\n\n\n\nStandardize features by removing the mean and scaling to unit variance.\nThe standard score of a sample x is calculated as: z = (x - u) / s, where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n\nscale = StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.fit_transform(x_test)\n\n\n#Logistic regression model fit on the training set\nlogreg = LogisticRegression(solver='lbfgs', max_iter=3000)\nlogreg.fit(x_train, y_train)\n\nLogisticRegression(max_iter=3000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=3000)\n\n\n\n#Using the trained model to predict the outcome for samples in x_test.\ny_pred = logreg.predict(x_test)\n\n\n#Return the probability estimates.\ny_score = logreg.predict_proba(x_test)[:, 1]\n\n\n\n\n\n\nPrecision: Percentage of correct positive predictions relative to total positive predictions.\nRecall: Percentage of correct positive predictions relative to total actual positives.\nF1 Score: A weighted harmonic mean of precision and recall. The closer to 1, the better the model. F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n\n\n#Comparing actual result and predicted result\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.78      0.93      0.85       127\n           1       0.78      0.48      0.59        65\n\n    accuracy                           0.78       192\n   macro avg       0.78      0.70      0.72       192\nweighted avg       0.78      0.78      0.76       192\n\n\n\n\nPrecision: Out of all the patients that the model predicted would get diabetes, 78% actually did.\nRecall: Out of all the patients that actually did get diabetes, the model predicted this outcome correctly for 48% of those patients.\nF1 Score: 0.59 - Since this value is close to 1, it tells us that the model does a good job of predicting whether or not patients will get diabetes. 2 * (Precision * Recall) / (Precision + Recall) ***** 2 * (.78 * .48) / (.78 + .48)\nSupport: These values is regarding how many patients belonged to each class in the test dataset. Among the patientis in the test dataset, 127 did not get diabetes and 65 did get diabetes.\n\n\n#The lower the RMS value, the better. O means the model is perfect.\nrms = mean_squared_error(y_test, y_pred, squared=False)\nrms\n\n0.4732423621500228\n\n\n\n\n\n\nThe ROC curve shows the trade-off between sensitivity (or True Positve Rate) and specificity (1 – False Positive Rate).\nClassifiers that give curves closer to the top-left corner indicate a better performance\nROC/AUC does not require to set a classification threshold and it’s still useful when there is high class imbalance\n\nROC curve can help you to choose a threshold that balances sensitivity and specificity in a way that makes sense for your particular context\nYou can’t actually see the thresholds used to generate the curve on the ROC curve itself\n\n\nfpr, tpr, thresh = roc_curve(y_test, y_score, pos_label=logreg.classes_[1])\n\n\n#AUC is the percentage of the ROC plot that is underneath the curve:\n# IMPORTANT: first argument is true values, second argument is predicted probabilities\nprint(metrics.roc_auc_score(y_test, y_pred))\n\n0.7030284675953968\n\n\n\nplt.figure(figsize=(6,4))\nplt.plot(fpr, tpr, linewidth=1, marker='.', label='Logistic')\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.rcParams['font.size'] = 8\nplt.title('ROC curve')\nplt.xlabel('Specificity (FPR)')\nplt.ylabel('Sensitivity (TPR)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPercentage of correct predictions\n\nprint('Accuracy of Logistic regression model is {}'.format(accuracy_score(y_test,y_pred)))\n\nAccuracy of Logistic regression model is 0.7760416666666666\n\n\n\n\n\nNull accuracy refers to the accuracy that could be achieved by always predicting the most frequent class in the dataset.\nIn the test set, 66% (127) of patients did not have diabetes, while 34% did. In this case, the null accuracy would be 66%, because if we always predicted “not diabetes,” we would be correct 66% of the time.\n\ny_test.value_counts().head(1) / len(y_test)\n\nOutcome\n0    0.661458\nName: count, dtype: float64\n\n\nAs the null accuracy is less than model accuracy, it indicates a good result.\n\n\n\n#print the 25 first true and predict responses\nprint ('True:'), y_test.values[0:25]\n\nTrue:\n\n\n(None,\n array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n        0, 0, 0]))\n\n\n\nprint ('Pred:'), y_pred[0:25]\n\nPred:\n\n\n(None,\n array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n        0, 0, 1]))\n\n\n\n\n\n\nConfusion matrix allows to calculate a variety of metrics. It’s a useful for multi-class problems (more than two response classes)\n\nEvery observation in the testing set is represented in exactly one box\nIt’s 2x2 matrix because there are 2 responses classes\nThe format shown here is not universal\n\nBasic Terminology\n\nTP: correctly predict that they have diabetes\nTN: correctly predict that they do not have diabetes\nFP: incorrectly predict that they do have diabetes\nFN: incorrectly predict that they do not have diabetes\n\n\n#IMPORTANT: First argument is true values, second argument is predict values\nmetrics.confusion_matrix(y_test, y_pred)\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n#Graphic visualization\ncm = confusion_matrix(y_test, y_pred, labels=logreg.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\ndisp.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nTN: 118 patients without diabetes were correctly predicted as no diabetics\nFP: 9 patients without diabetes were incorrectly predicted as diabetics\nFN: 34 patients with diabetes were incorrectly predicted as no diabetics\nTP: 31 patients with diabetes were correctly predicted as diabetics\n\n\n#save confusion matrix and slice into four pieces\nconfusion = metrics.confusion_matrix(y_test, y_pred)\nTN = confusion[0,0]\nFP = confusion[0,1]\nFN = confusion[1,0]\nTP = confusion[1,1]\nconfusion\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n\n\n#How often the classifier is correct?\nprint('Accuracy: {}'.format((TP + TN) / (TP + TN + FP + FN)))\n#print('Accuracy: {}'.format(metrics.accuracy_score(y_test, y_pred_class)))\n\nAccuracy: 0.7760416666666666\n\n\n\n\n\nThe k-fold cross-validation procedure divides a limited dataset into k non-overlapping folds. Each of the k folds is given an opportunity to be used as a held back test set, whilst all other folds collectively are used as a training dataset. A total of k models are fit and evaluated on the k hold-out test sets and the mean performance is reported.\n\n#This will give the overall accuracy of your model .\nkf = KFold(n_splits=10, random_state=1, shuffle=True)\ncv_result = cross_val_score(logreg, x, y, cv=kf, scoring='accuracy', n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(cv_result), std(cv_result)))\n\nAccuracy: 0.784 (0.033)\n\n\n\n#How often the classifier is incorrect?\nprint('Error: {}'.format((FP + FN)/(TP + TN + FP + FN)))\n#print('Error: {}'.format(1-metrics.accuracy_score(y_test, y_pred_class)))\n\nError: 0.22395833333333334\n\n\n\n#When the actual value is positive, how often is the prediction correct?\nprint('Sensitivity (TPR): {}'.format(TP / (TP + FN)))\n#metrics.recall_score(y_test, y_pred_class)\n\nSensitivity (TPR): 0.47692307692307695\n\n\n\n#When the actual value is negative, how often is the prediction correct?\nprint('Specificity (FPR): {}'.format(TN / (TN + FP))) \n#recall_score(y_test, y_pred_class, pos_label=0)\n\nSpecificity (FPR): 0.9291338582677166\n\n\n\n#When a positive value is predicted, how often is the prediction correct?\nprint('Precision: {}'.format(TP / (TP + FP))) \n#metrics.precision_score(y_test, y_pred_class)\n\nPrecision: 0.775\n\n\n\n\n\n\nThe choice of metrics depends on the business objective.\nFor this project, sensibility (False Negative) is the metric most important, since predicting diabetics as no diabetics is the worst expected error. This may imply no further investigations and consequently no treatment of the disease.\nSo the better result is to have a Sensitivity (The correct prediction for positive values) result higher than a Specificity (The correct prediction for negative values) result.\nThe error in predicting a healthy patient as a diabetic patient is more acceptable than the opposite.\n\n\n\n\n#print the first 10 predicted responses\nlogreg.predict(x_test)[0:10]\n\narray([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n\n\n\n#print the first 10 predicted probabilities of class membership\nlogreg.predict_proba(x_test)[0:10, :]\n\narray([[0.83358342, 0.16641658],\n       [0.80138151, 0.19861849],\n       [0.95231282, 0.04768718],\n       [0.87348851, 0.12651149],\n       [0.67158939, 0.32841061],\n       [0.38292382, 0.61707618],\n       [0.93226643, 0.06773357],\n       [0.5219636 , 0.4780364 ],\n       [0.92950252, 0.07049748],\n       [0.69118097, 0.30881903]])\n\n\n\n#print the first 10 predicted probabilities for class 1\nlogreg.predict_proba(x_test)[0:10, 1]\n\narray([0.16641658, 0.19861849, 0.04768718, 0.12651149, 0.32841061,\n       0.61707618, 0.06773357, 0.4780364 , 0.07049748, 0.30881903])\n\n\n\nfig = sns.histplot(data=y_score, bins=8)\nplt.xlabel(\"Predicted probability of diabetes\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of predicted probabilities\") \nplt.xlim(0,1)\nplt.rcParams['font.size']=10\nplt.show(fig)\n\n\n\n\n\n\n\n\n\n\nThreshold of 0.5 is used by default (for binary problems) to convert predicted possibilities into class predictions Threshold can be adjusted to increase sensitivity or specificity Sensitivity and specificity have an inverse relationship\n\n# calculate roc curves\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\n\n\n# calculate the g-mean for each threshold\ngmeans = sqrt(tpr * (1-fpr))\n# locate the index of the largest g-mean\nix = argmax(gmeans)\nprint('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n\nBest Threshold=0.242365, G-Mean=0.796\n\n\n\n# get the best threshold\nJ = tpr - fpr\nix = argmax(J)\nbest_thresh = thresholds[ix]\nprint('Best Threshold=%f' % (best_thresh))\n\nBest Threshold=0.242365\n\n\n\n# define a function that accepts a threshold and prints sensitivity and specificity\ndef evaluate_threshold(threshold):\n    print('Sensitivity:', tpr[thresholds &gt; threshold][-1])\n    print('Specificity:', 1 - fpr[thresholds &gt; threshold][-1])\n\n\nevaluate_threshold(0.5)\n\nSensitivity: 0.47692307692307695\nSpecificity: 0.9291338582677166\n\n\n\nevaluate_threshold(0.3)\n\nSensitivity: 0.7230769230769231\nSpecificity: 0.7795275590551181\n\n\n\nevaluate_threshold(0.242365)\n\nSensitivity: 0.8461538461538461\nSpecificity: 0.7480314960629921\n\n\n\n#predict diabetes if the predicted probabilities is greater than 0.242365\ny_pred_2 = preprocessing.binarize([y_score], threshold=0.242365)[0]\n\n\n#print the first 10 predicted probabilites\ny_pred[0:10]\n\narray([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n\n\n\n#print the first 10 predicted classes with the lower threshold\ny_pred_2[0:10]\n\narray([0., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n\n\n\n#previous confusion matrix (default threshold of 0.5)\nconfusion\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n#now confusion matrix (threshold of 0.3)\nconfusion_2 = metrics.confusion_matrix(y_test, y_pred_2)\nTN = confusion_2[0,0]\nFP = confusion_2[0,1]\nFN = confusion_2[1,0]\nTP = confusion_2[1,1]\n\n\nconfusion_2\n\narray([[95, 32],\n       [10, 55]])\n\n\n\n#sensitivity has increased (used to be 0.7384615384615385)\nprint('Sensitivity (TPR): {}'.format(TP / (TP + FN)))\n\nSensitivity (TPR): 0.8461538461538461\n\n\n\n#sensitivity has increased (used to be 0.7795275590551181)\nprint('Specificity (FPR): {}'.format(TN / (TN + FP))) \n\nSpecificity (FPR): 0.7480314960629921\n\n\n\n#AUC is the percentage of the ROC plot that is underneath the curve:\nprint(metrics.roc_auc_score(y_test, y_pred_2))\n\n0.7970926711084192\n\n\n\n\n\n\nWith a threshold of 0.242365, the sensitivity has increased from 0.48 to 0.85, and the specificity has decreased from 0.93 to 0.75. Despite the decrease in specificity, for this project, the most important metric is sensitivity, once we want to correctly predict the patients with diabetes, the correct prediction for positive values.\nThe AUC has also increased after threshold adjustment, from 0.70 to 0.79.",
    "crumbs": [
      "Projects",
      "2. Prediction of Diabetes"
    ]
  },
  {
    "objectID": "project2.html#correlations",
    "href": "project2.html#correlations",
    "title": "2. Prediction of Diabetes",
    "section": "",
    "text": "Each square shows the correlation between the variables on each axis. Correlation ranges from -1 to +1.\n\nValues closer to 0: There is no linear trend between the two variables.\nValues closer to 1: The correlation is positive; that is as one increases so does the other and the closer to 1 the stronger this relationship is.\nValues closer to -1: One variable will decrease as the other increases\n\nThe diagonals are all 1/dark because those squares are correlating each variable to itself (so it’s a perfect correlation). For the rest the larger the number and darker the color the higher the correlation between the two variables.\n\n\n\n\nThere is a strong positve correlation between Pregnancies and Age, Glucose and Outcome. There is a strong negative correlation between Skinthickness and Age, Pregnancies and SkinThickness, Pregnance and Insulin\n\n#Correlation of features with the Outcome\ncorr_report = pima.corr()['Outcome']\ncorr_report.sort_values(ascending=False)\n\nOutcome                     1.000000\nGlucose                     0.466581\nBMI                         0.292695\nAge                         0.238356\nPregnancies                 0.221898\nDiabetesPedigreeFunction    0.173844\nInsulin                     0.130548\nSkinThickness               0.074752\nBloodPressure               0.065068\nName: Outcome, dtype: float64\n\n\n\noutliers = pima[pima['Glucose'] &gt; 150]\noutliers\n\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n8\n2\n197\n70\n45\n543\n30.5\n0.158\n53\n1\n\n\n11\n10\n168\n74\n0\n0\n38.0\n0.537\n34\n1\n\n\n13\n1\n189\n60\n23\n846\n30.1\n0.398\n59\n1\n\n\n14\n5\n166\n72\n19\n175\n25.8\n0.587\n51\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n749\n6\n162\n62\n0\n0\n24.3\n0.178\n50\n1\n\n\n753\n0\n181\n88\n44\n510\n43.3\n0.222\n26\n1\n\n\n754\n8\n154\n78\n32\n0\n32.4\n0.443\n45\n1\n\n\n759\n6\n190\n92\n0\n0\n35.5\n0.278\n66\n1\n\n\n761\n9\n170\n74\n31\n0\n44.0\n0.403\n43\n1\n\n\n\n\n140 rows × 9 columns\n\n\n\n\n\noutliers['Outcome'].value_counts()\n\nOutcome\n1    105\n0     35\nName: count, dtype: int64\n\n\n\n# Histogram to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.histplot(value, ax=ax[index], kde=True, stat=\"density\", linewidth=0)\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.8, w_pad=0.5, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n# Boxplot to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.boxplot(value, ax=ax[index])\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n\n\n\nThere are some outliers analyzed through the distribution of data in the histograms and boxplots.\nThey following code has removed the outliers before to proceed with the ML model.\n\n\nThe lower quartile corresponds with the 25th percentile and the upper quartile corresponds with the 75th percentile, so IQR = Q3 − Q1.\nThe IQR is an example of a trimmed estimator, defined as the 25% trimmed range, which enhances the accuracy of dataset statistics by dropping lower contribution, outlying points.\n\nQ1 = pima.quantile(0.25)\nQ3 = pima.quantile(0.75)\n\n\nIQR = Q3 - Q1\nIQR\n\nPregnancies                   5.0000\nGlucose                      41.2500\nBloodPressure                18.0000\nSkinThickness                32.0000\nInsulin                     127.2500\nBMI                           9.3000\nDiabetesPedigreeFunction      0.3825\nAge                          17.0000\nOutcome                       1.0000\ndtype: float64\n\n\n\npima.shape\n\n(768, 9)\n\n\n\nThe interquartile range is often used to find outliers in data. Outliers here are defined as observations that fall below Q1 − 1.5 IQR or above Q3 + 1.5 IQR. In a boxplot, the highest and lowest occurring value within this limit are indicated by whiskers of the box (frequently with an additional bar at the end of the whisker) and any outliers as individual points.\n\n\n# Outlier removal\npima = pima[~((pima &lt; (Q1 - 1.5 * IQR)) | (pima &gt; (Q3 + 1.5 * IQR))).any(axis = 1)]\npima.shape\n\n(639, 9)\n\n\n\ncount = pima[\"Outcome\"].value_counts()\ncount\n\nOutcome\n0    439\n1    200\nName: count, dtype: int64\n\n\n\n# Data distribution\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.boxplot(value, ax=ax[index])\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n# Histogram to analyze the distribution of data\nfig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15,12))\nindex = 0\nax = ax.flatten()\n\nfor col, value in pima.items():\n    col_dist = sns.histplot(value, ax=ax[index], kde=True, stat=\"density\", linewidth=0)\n    col_dist.set_xlabel(col,fontsize=10)\n    col_dist.set_ylabel('density',fontsize=10)\n    index += 1\nplt.tight_layout(pad=0.8, w_pad=0.5, h_pad=5.0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Define x and y\nfeature_cols =['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\nx=pima[feature_cols]\ny=pima.Outcome\n\n\n#split x and y into training (70%) and testing (30%) sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=0)\n\n\n\n\n\nStandardize features by removing the mean and scaling to unit variance.\nThe standard score of a sample x is calculated as: z = (x - u) / s, where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n\nscale = StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.fit_transform(x_test)\n\n\n#Logistic regression model fit on the training set\nlogreg = LogisticRegression(solver='lbfgs', max_iter=3000)\nlogreg.fit(x_train, y_train)\n\nLogisticRegression(max_iter=3000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=3000)\n\n\n\n#Using the trained model to predict the outcome for samples in x_test.\ny_pred = logreg.predict(x_test)\n\n\n#Return the probability estimates.\ny_score = logreg.predict_proba(x_test)[:, 1]\n\n\n\n\n\n\nPrecision: Percentage of correct positive predictions relative to total positive predictions.\nRecall: Percentage of correct positive predictions relative to total actual positives.\nF1 Score: A weighted harmonic mean of precision and recall. The closer to 1, the better the model. F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n\n\n#Comparing actual result and predicted result\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.78      0.93      0.85       127\n           1       0.78      0.48      0.59        65\n\n    accuracy                           0.78       192\n   macro avg       0.78      0.70      0.72       192\nweighted avg       0.78      0.78      0.76       192\n\n\n\n\nPrecision: Out of all the patients that the model predicted would get diabetes, 78% actually did.\nRecall: Out of all the patients that actually did get diabetes, the model predicted this outcome correctly for 48% of those patients.\nF1 Score: 0.59 - Since this value is close to 1, it tells us that the model does a good job of predicting whether or not patients will get diabetes. 2 * (Precision * Recall) / (Precision + Recall) ***** 2 * (.78 * .48) / (.78 + .48)\nSupport: These values is regarding how many patients belonged to each class in the test dataset. Among the patientis in the test dataset, 127 did not get diabetes and 65 did get diabetes.\n\n\n#The lower the RMS value, the better. O means the model is perfect.\nrms = mean_squared_error(y_test, y_pred, squared=False)\nrms\n\n0.4732423621500228\n\n\n\n\n\n\nThe ROC curve shows the trade-off between sensitivity (or True Positve Rate) and specificity (1 – False Positive Rate).\nClassifiers that give curves closer to the top-left corner indicate a better performance\nROC/AUC does not require to set a classification threshold and it’s still useful when there is high class imbalance\n\nROC curve can help you to choose a threshold that balances sensitivity and specificity in a way that makes sense for your particular context\nYou can’t actually see the thresholds used to generate the curve on the ROC curve itself\n\n\nfpr, tpr, thresh = roc_curve(y_test, y_score, pos_label=logreg.classes_[1])\n\n\n#AUC is the percentage of the ROC plot that is underneath the curve:\n# IMPORTANT: first argument is true values, second argument is predicted probabilities\nprint(metrics.roc_auc_score(y_test, y_pred))\n\n0.7030284675953968\n\n\n\nplt.figure(figsize=(6,4))\nplt.plot(fpr, tpr, linewidth=1, marker='.', label='Logistic')\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.rcParams['font.size'] = 8\nplt.title('ROC curve')\nplt.xlabel('Specificity (FPR)')\nplt.ylabel('Sensitivity (TPR)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPercentage of correct predictions\n\nprint('Accuracy of Logistic regression model is {}'.format(accuracy_score(y_test,y_pred)))\n\nAccuracy of Logistic regression model is 0.7760416666666666\n\n\n\n\n\nNull accuracy refers to the accuracy that could be achieved by always predicting the most frequent class in the dataset.\nIn the test set, 66% (127) of patients did not have diabetes, while 34% did. In this case, the null accuracy would be 66%, because if we always predicted “not diabetes,” we would be correct 66% of the time.\n\ny_test.value_counts().head(1) / len(y_test)\n\nOutcome\n0    0.661458\nName: count, dtype: float64\n\n\nAs the null accuracy is less than model accuracy, it indicates a good result.\n\n\n\n#print the 25 first true and predict responses\nprint ('True:'), y_test.values[0:25]\n\nTrue:\n\n\n(None,\n array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n        0, 0, 0]))\n\n\n\nprint ('Pred:'), y_pred[0:25]\n\nPred:\n\n\n(None,\n array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n        0, 0, 1]))\n\n\n\n\n\n\nConfusion matrix allows to calculate a variety of metrics. It’s a useful for multi-class problems (more than two response classes)\n\nEvery observation in the testing set is represented in exactly one box\nIt’s 2x2 matrix because there are 2 responses classes\nThe format shown here is not universal\n\nBasic Terminology\n\nTP: correctly predict that they have diabetes\nTN: correctly predict that they do not have diabetes\nFP: incorrectly predict that they do have diabetes\nFN: incorrectly predict that they do not have diabetes\n\n\n#IMPORTANT: First argument is true values, second argument is predict values\nmetrics.confusion_matrix(y_test, y_pred)\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n#Graphic visualization\ncm = confusion_matrix(y_test, y_pred, labels=logreg.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\ndisp.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nTN: 118 patients without diabetes were correctly predicted as no diabetics\nFP: 9 patients without diabetes were incorrectly predicted as diabetics\nFN: 34 patients with diabetes were incorrectly predicted as no diabetics\nTP: 31 patients with diabetes were correctly predicted as diabetics\n\n\n#save confusion matrix and slice into four pieces\nconfusion = metrics.confusion_matrix(y_test, y_pred)\nTN = confusion[0,0]\nFP = confusion[0,1]\nFN = confusion[1,0]\nTP = confusion[1,1]\nconfusion\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n\n\n#How often the classifier is correct?\nprint('Accuracy: {}'.format((TP + TN) / (TP + TN + FP + FN)))\n#print('Accuracy: {}'.format(metrics.accuracy_score(y_test, y_pred_class)))\n\nAccuracy: 0.7760416666666666\n\n\n\n\n\nThe k-fold cross-validation procedure divides a limited dataset into k non-overlapping folds. Each of the k folds is given an opportunity to be used as a held back test set, whilst all other folds collectively are used as a training dataset. A total of k models are fit and evaluated on the k hold-out test sets and the mean performance is reported.\n\n#This will give the overall accuracy of your model .\nkf = KFold(n_splits=10, random_state=1, shuffle=True)\ncv_result = cross_val_score(logreg, x, y, cv=kf, scoring='accuracy', n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(cv_result), std(cv_result)))\n\nAccuracy: 0.784 (0.033)\n\n\n\n#How often the classifier is incorrect?\nprint('Error: {}'.format((FP + FN)/(TP + TN + FP + FN)))\n#print('Error: {}'.format(1-metrics.accuracy_score(y_test, y_pred_class)))\n\nError: 0.22395833333333334\n\n\n\n#When the actual value is positive, how often is the prediction correct?\nprint('Sensitivity (TPR): {}'.format(TP / (TP + FN)))\n#metrics.recall_score(y_test, y_pred_class)\n\nSensitivity (TPR): 0.47692307692307695\n\n\n\n#When the actual value is negative, how often is the prediction correct?\nprint('Specificity (FPR): {}'.format(TN / (TN + FP))) \n#recall_score(y_test, y_pred_class, pos_label=0)\n\nSpecificity (FPR): 0.9291338582677166\n\n\n\n#When a positive value is predicted, how often is the prediction correct?\nprint('Precision: {}'.format(TP / (TP + FP))) \n#metrics.precision_score(y_test, y_pred_class)\n\nPrecision: 0.775\n\n\n\n\n\n\nThe choice of metrics depends on the business objective.\nFor this project, sensibility (False Negative) is the metric most important, since predicting diabetics as no diabetics is the worst expected error. This may imply no further investigations and consequently no treatment of the disease.\nSo the better result is to have a Sensitivity (The correct prediction for positive values) result higher than a Specificity (The correct prediction for negative values) result.\nThe error in predicting a healthy patient as a diabetic patient is more acceptable than the opposite.\n\n\n\n\n#print the first 10 predicted responses\nlogreg.predict(x_test)[0:10]\n\narray([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n\n\n\n#print the first 10 predicted probabilities of class membership\nlogreg.predict_proba(x_test)[0:10, :]\n\narray([[0.83358342, 0.16641658],\n       [0.80138151, 0.19861849],\n       [0.95231282, 0.04768718],\n       [0.87348851, 0.12651149],\n       [0.67158939, 0.32841061],\n       [0.38292382, 0.61707618],\n       [0.93226643, 0.06773357],\n       [0.5219636 , 0.4780364 ],\n       [0.92950252, 0.07049748],\n       [0.69118097, 0.30881903]])\n\n\n\n#print the first 10 predicted probabilities for class 1\nlogreg.predict_proba(x_test)[0:10, 1]\n\narray([0.16641658, 0.19861849, 0.04768718, 0.12651149, 0.32841061,\n       0.61707618, 0.06773357, 0.4780364 , 0.07049748, 0.30881903])\n\n\n\nfig = sns.histplot(data=y_score, bins=8)\nplt.xlabel(\"Predicted probability of diabetes\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of predicted probabilities\") \nplt.xlim(0,1)\nplt.rcParams['font.size']=10\nplt.show(fig)\n\n\n\n\n\n\n\n\n\n\nThreshold of 0.5 is used by default (for binary problems) to convert predicted possibilities into class predictions Threshold can be adjusted to increase sensitivity or specificity Sensitivity and specificity have an inverse relationship\n\n# calculate roc curves\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\n\n\n# calculate the g-mean for each threshold\ngmeans = sqrt(tpr * (1-fpr))\n# locate the index of the largest g-mean\nix = argmax(gmeans)\nprint('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n\nBest Threshold=0.242365, G-Mean=0.796\n\n\n\n# get the best threshold\nJ = tpr - fpr\nix = argmax(J)\nbest_thresh = thresholds[ix]\nprint('Best Threshold=%f' % (best_thresh))\n\nBest Threshold=0.242365\n\n\n\n# define a function that accepts a threshold and prints sensitivity and specificity\ndef evaluate_threshold(threshold):\n    print('Sensitivity:', tpr[thresholds &gt; threshold][-1])\n    print('Specificity:', 1 - fpr[thresholds &gt; threshold][-1])\n\n\nevaluate_threshold(0.5)\n\nSensitivity: 0.47692307692307695\nSpecificity: 0.9291338582677166\n\n\n\nevaluate_threshold(0.3)\n\nSensitivity: 0.7230769230769231\nSpecificity: 0.7795275590551181\n\n\n\nevaluate_threshold(0.242365)\n\nSensitivity: 0.8461538461538461\nSpecificity: 0.7480314960629921\n\n\n\n#predict diabetes if the predicted probabilities is greater than 0.242365\ny_pred_2 = preprocessing.binarize([y_score], threshold=0.242365)[0]\n\n\n#print the first 10 predicted probabilites\ny_pred[0:10]\n\narray([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n\n\n\n#print the first 10 predicted classes with the lower threshold\ny_pred_2[0:10]\n\narray([0., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n\n\n\n#previous confusion matrix (default threshold of 0.5)\nconfusion\n\narray([[118,   9],\n       [ 34,  31]])\n\n\n\n#now confusion matrix (threshold of 0.3)\nconfusion_2 = metrics.confusion_matrix(y_test, y_pred_2)\nTN = confusion_2[0,0]\nFP = confusion_2[0,1]\nFN = confusion_2[1,0]\nTP = confusion_2[1,1]\n\n\nconfusion_2\n\narray([[95, 32],\n       [10, 55]])\n\n\n\n#sensitivity has increased (used to be 0.7384615384615385)\nprint('Sensitivity (TPR): {}'.format(TP / (TP + FN)))\n\nSensitivity (TPR): 0.8461538461538461\n\n\n\n#sensitivity has increased (used to be 0.7795275590551181)\nprint('Specificity (FPR): {}'.format(TN / (TN + FP))) \n\nSpecificity (FPR): 0.7480314960629921\n\n\n\n#AUC is the percentage of the ROC plot that is underneath the curve:\nprint(metrics.roc_auc_score(y_test, y_pred_2))\n\n0.7970926711084192\n\n\n\n\n\n\nWith a threshold of 0.242365, the sensitivity has increased from 0.48 to 0.85, and the specificity has decreased from 0.93 to 0.75. Despite the decrease in specificity, for this project, the most important metric is sensitivity, once we want to correctly predict the patients with diabetes, the correct prediction for positive values.\nThe AUC has also increased after threshold adjustment, from 0.70 to 0.79.",
    "crumbs": [
      "Projects",
      "2. Prediction of Diabetes"
    ]
  },
  {
    "objectID": "project1.html#preparación-de-datos",
    "href": "project1.html#preparación-de-datos",
    "title": "1. Classification Dimensions Analysis",
    "section": "Preparación de datos:",
    "text": "Preparación de datos:\nAplicación de un filtro de exclusión para descartar registros que tengan valores fuera del rango de 1 a 5\n\n# Definir rango válido de 1 a 5\nvalid_range = set(range(1, 6))\n# Función para filtrar filas según el rango válido\ndef is_valid(row):\n    return all(value in valid_range for value in row)\n# Aplicar la función de filtro a cada fila.\ndf_cleaned = df[df.apply(is_valid, axis=1)]\ndf_cleaned.describe()\n\n\n\n\n\n\n\n\n\nt1scs1\nt1scs2\nt1scs3\nt1scs4\nt1scs5\nt1scs6\nt1scs7\nt1scs8\nt1scs9\nt1scs10\n...\nt3cbq12\nt3cbq13\nt3cbq14\nt3cbq15\nt3ssq1\nt3ssq2\nt3ssq3\nt3ssq4\nt3ssq5\nt3ssq6\n\n\n\n\ncount\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n...\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n\n\nmean\n3.484496\n3.457364\n4.193798\n4.263566\n3.182171\n3.003876\n3.903101\n3.620155\n3.635659\n2.701550\n...\n2.050388\n1.701550\n1.887597\n1.620155\n3.926357\n4.461240\n4.251938\n4.217054\n4.259690\n4.228682\n\n\nstd\n1.018196\n0.895364\n0.695483\n0.908408\n1.137336\n1.075001\n0.819456\n1.085409\n1.009203\n1.150232\n...\n0.904689\n0.808562\n0.665259\n0.781038\n0.807554\n0.827806\n0.856706\n0.886222\n0.985499\n1.042870\n\n\nmin\n1.000000\n1.000000\n2.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n25%\n3.000000\n3.000000\n4.000000\n4.000000\n2.000000\n2.000000\n3.000000\n3.000000\n3.000000\n2.000000\n...\n1.000000\n1.000000\n1.000000\n1.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n\n\n50%\n3.000000\n4.000000\n4.000000\n4.500000\n3.000000\n3.000000\n4.000000\n4.000000\n4.000000\n3.000000\n...\n2.000000\n2.000000\n2.000000\n1.000000\n4.000000\n5.000000\n4.000000\n4.000000\n5.000000\n5.000000\n\n\n75%\n4.000000\n4.000000\n5.000000\n5.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n...\n3.000000\n2.000000\n2.000000\n2.000000\n4.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n\n\nmax\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n...\n5.000000\n5.000000\n4.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n\n\n\n\n8 rows × 99 columns",
    "crumbs": [
      "Projects",
      "1. Classification Dimensions Analysis"
    ]
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "LLM - ChatGPT applied on Specific Context",
    "section": "",
    "text": "Devido aos avanços da IA Generativa com os LLMs, o ChatGPT, desenvolvido pela OpenAI, tornou-se uma ferramenta popular para geração de texto. Através da interface em https://chat.openai.com/, os usuários podem interagir com o ChatGPT para receber respostas, resumos de texto e traduções. No entanto, para responder a perguntas específicas de contexto inédito, como as baseadas em um documento PDF, é geralmente necessário usar a API do ChatGPT.\n\n\nPara simplificar essa tarefa, surgiu o LangChain https://www.langchain.com/, uma estrutura de código aberto que facilita o desenvolvimento de aplicativos com LLMs. O LangChain atua como uma interface genérica para diferentes LLMs, permitindo a construção de aplicativos LLM integrados a fontes de dados externas.\n\n\nEste projeto visa demonstrar a aplicação prática do ChatGPT em um contexto específico com o auxílio do LangChain, explorando cada etapa e os principais desafios envolvidos."
  },
  {
    "objectID": "project3.html#setup-and-constants",
    "href": "project3.html#setup-and-constants",
    "title": "LLM - ChatGPT applied on Specific Context",
    "section": "Setup and Constants:",
    "text": "Setup and Constants:\nImportando todos os módulos necessários os quais já foram previamente instalados.\n\n# Setup\nfrom langchain.text_splitter             import RecursiveCharacterTextSplitter # Split - Tokenization\nfrom langchain.embeddings                import OpenAIEmbeddings               # Embeddings\nfrom langchain.vectorstores              import Chroma                         # Vector Store\nfrom langchain.llms                      import OpenAI                         # Models\nfrom langchain.chat_models               import ChatOpenAI                     # Chat\nfrom langchain.chains.question_answering import load_qa_chain                  # QA\nfrom langchain.callbacks                 import get_openai_callback            # Callback\nimport os\nimport textract\nimport warnings\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None) \n\nDefinindo as constantes que serão utilizadas ao longo do código.\n\n# Constants\nOPENAI_API_KEY       = os.environ.get('OPENAI_API_KEY')        # Definida como variável de ambiente\nFILE_PATH_CONTEXT    = \"./source/project1/context/ValeskaAlves.pdf\" # Path para o arquivo de contexto\nEMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"                # Modelo para o embedding do contexto\nFILE_PATH_DB         = \"./source/project1/chroma/\"             # Path para Vector Store\nMODEL_NAME           = \"gpt-3.5-turbo\"                         # Modelo para responder as perguntas"
  },
  {
    "objectID": "project3.html#document-loading",
    "href": "project3.html#document-loading",
    "title": "LLM - ChatGPT applied on Specific Context",
    "section": "Document Loading",
    "text": "Document Loading\nAqui carregamos o arquivo de contexto, que pode estar em qualquer formato (https://textract.readthedocs.io/en/stable/) e convertemos em uma string.\n\n# Document Loading\nfile_path = FILE_PATH_CONTEXT\ndoc       = textract.process(file_path)\ntext      = doc.decode('utf-8')"
  },
  {
    "objectID": "project3.html#document-splitting---tokenization",
    "href": "project3.html#document-splitting---tokenization",
    "title": "LLM - ChatGPT applied on Specific Context",
    "section": "Document Splitting - Tokenization",
    "text": "Document Splitting - Tokenization\nNesta etapa, nosso objetivo é segmentar o contexto em vários documentos, com a principal ideia de dividir o texto em unidades semanticamente relevantes.\nPor simplicidade, essa divisão será feita considerando um número máximo de caracteres por documento, levando em conta a estrutura textual original, ou seja, espaços em branco, quebras de linhas e parágrafos podem ser considerados como separadores aqui.\nExistem diversas técnicas para efetuar este processo, estamos usando apenas uma delas.\n\n# Document Splitting - Tokenization\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size      = 512, # Quantidade máxima de caracteres por split\n    chunk_overlap   = 24,  # Quantidade de máxima de caracteres sobrepostos por split\n)\n\nchunks = text_splitter.create_documents([text])"
  },
  {
    "objectID": "project1.html#introduction",
    "href": "project1.html#introduction",
    "title": "1. Classification Dimensions Analysis",
    "section": "",
    "text": "This report presents a classification of students based on the dimensions of self-compassion, burnout, and perceived social support.\n\nimport openpyxl\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2_contingency\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n\ndf = pd.read_excel('./source/DATA_Coaches.xlsx',engine='openpyxl')\n\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nt1scs1\nt1scs2\nt1scs3\nt1scs4\nt1scs5\nt1scs6\nt1scs7\nt1scs8\nt1scs9\nt1scs10\n...\nt3cbq12\nt3cbq13\nt3cbq14\nt3cbq15\nt3ssq1\nt3ssq2\nt3ssq3\nt3ssq4\nt3ssq5\nt3ssq6\n\n\n\n\ncount\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n...\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n422.000000\n\n\nmean\n8.099526\n8.201422\n8.860190\n8.855450\n7.950237\n7.744076\n8.644550\n8.180095\n8.225118\n7.412322\n...\n387.127962\n386.914692\n382.395735\n386.864929\n388.277251\n388.606635\n388.478673\n388.457346\n388.483412\n388.464455\n\n\nstd\n67.638234\n68.458283\n68.410955\n67.585122\n68.479342\n68.492494\n68.426785\n67.634590\n67.630153\n68.516764\n...\n485.981977\n486.151265\n480.209295\n486.190762\n485.069049\n484.807454\n484.909119\n484.926090\n484.905504\n484.920634\n\n\nmin\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n25%\n3.000000\n3.000000\n4.000000\n4.000000\n2.000000\n2.000000\n4.000000\n3.000000\n3.000000\n2.000000\n...\n2.000000\n1.000000\n2.000000\n1.000000\n4.000000\n5.000000\n4.000000\n4.000000\n4.000000\n4.000000\n\n\n50%\n3.000000\n4.000000\n4.000000\n4.000000\n3.000000\n3.000000\n4.000000\n4.000000\n4.000000\n3.000000\n...\n3.000000\n2.000000\n2.000000\n2.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n\n\n75%\n4.000000\n4.000000\n5.000000\n5.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n...\n999.000000\n999.000000\n987.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n\n\nmax\n987.000000\n999.000000\n999.000000\n987.000000\n999.000000\n999.000000\n999.000000\n987.000000\n987.000000\n999.000000\n...\n999.000000\n999.000000\n987.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n999.000000\n\n\n\n\n8 rows × 99 columns",
    "crumbs": [
      "Projects",
      "1. Classification Dimensions Analysis"
    ]
  },
  {
    "objectID": "project1.html#función-para-invertir-la-puntuación",
    "href": "project1.html#función-para-invertir-la-puntuación",
    "title": "1. Classification Dimensions Analysis",
    "section": "Función para invertir la puntuación",
    "text": "Función para invertir la puntuación\nFunción para invertir la puntuación de los ítems de las escalas incorporadas en la base de datos “DATA_coaches”. A pesar que en esta base de datos todas las escalas tienen el mismo rango en la escala ordinal (de 1 a 5 puntos) haced que la función permita trabajar con cualquier escala ordinal a la que se le quiera invertir la puntuación.\n\ndef invert_values(df, value_max, value_min, columns_to_invert):\n    df_inverted = df.copy()\n    df_inverted[columns_to_invert] = value_max + value_min - df[columns_to_invert]\n    return df_inverted\n\nUtilizad la función anterior para invertir los ítems descritos en la Tabla 1 cuya codificación reza como inversa. Hecho esto, guardad estas nuevas variables sobre las originales.\n\nvalue_max = df_cleaned.max().max()\nvalue_min = df_cleaned.min().min()\n\n# Columns to apply the function on\ncolumns_to_invert = [\n't1scs1', 't1scs4', 't1scs8', 't1scs9', 't1scs11', 't1scs12', \n't2scs1', 't2scs4', 't2scs8', 't2scs9', 't2scs11', 't2scs12', \n't3scs1', 't3scs4', 't3scs8', 't3scs9', 't3scs11', 't3scs12', \n't1cbq1', 't1cbq14',\n't2cbq1', 't2cbq14', \n't3cbq1', 't3cbq14']\n\n# Invert values for specified columns using the function\ndf_inverted = invert_values(df_cleaned, value_max, value_min, columns_to_invert)\n\ndf_inverted.describe()\n\n\n\n\n\n\n\n\n\nt1scs1\nt1scs2\nt1scs3\nt1scs4\nt1scs5\nt1scs6\nt1scs7\nt1scs8\nt1scs9\nt1scs10\n...\nt3cbq12\nt3cbq13\nt3cbq14\nt3cbq15\nt3ssq1\nt3ssq2\nt3ssq3\nt3ssq4\nt3ssq5\nt3ssq6\n\n\n\n\ncount\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n...\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n\n\nmean\n2.515504\n3.457364\n4.193798\n1.736434\n3.182171\n3.003876\n3.903101\n2.379845\n2.364341\n2.701550\n...\n2.050388\n1.701550\n4.112403\n1.620155\n3.926357\n4.461240\n4.251938\n4.217054\n4.259690\n4.228682\n\n\nstd\n1.018196\n0.895364\n0.695483\n0.908408\n1.137336\n1.075001\n0.819456\n1.085409\n1.009203\n1.150232\n...\n0.904689\n0.808562\n0.665259\n0.781038\n0.807554\n0.827806\n0.856706\n0.886222\n0.985499\n1.042870\n\n\nmin\n1.000000\n1.000000\n2.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n2.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n25%\n2.000000\n3.000000\n4.000000\n1.000000\n2.000000\n2.000000\n3.000000\n2.000000\n2.000000\n2.000000\n...\n1.000000\n1.000000\n4.000000\n1.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n4.000000\n\n\n50%\n3.000000\n4.000000\n4.000000\n1.500000\n3.000000\n3.000000\n4.000000\n2.000000\n2.000000\n3.000000\n...\n2.000000\n2.000000\n4.000000\n1.000000\n4.000000\n5.000000\n4.000000\n4.000000\n5.000000\n5.000000\n\n\n75%\n3.000000\n4.000000\n5.000000\n2.000000\n4.000000\n4.000000\n4.000000\n3.000000\n3.000000\n4.000000\n...\n3.000000\n2.000000\n5.000000\n2.000000\n4.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n\n\nmax\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n...\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n5.000000\n\n\n\n\n8 rows × 99 columns\n\n\n\n\nLos valores máximo y mínimo se mantuvieron iguales y se cambió la media. Prueba para comparar las escalas en la primera línea del df\n\ndf_cleaned.loc[:0]\n\n\n\n\n\n\n\n\n\nt1scs1\nt1scs2\nt1scs3\nt1scs4\nt1scs5\nt1scs6\nt1scs7\nt1scs8\nt1scs9\nt1scs10\n...\nt3cbq12\nt3cbq13\nt3cbq14\nt3cbq15\nt3ssq1\nt3ssq2\nt3ssq3\nt3ssq4\nt3ssq5\nt3ssq6\n\n\n\n\n0\n3\n4\n4\n5\n3\n3\n3\n4\n4\n2\n...\n2\n2\n2\n1\n4\n4\n5\n4\n4\n5\n\n\n\n\n1 rows × 99 columns\n\n\n\n\n\ndf_inverted.loc[:0]\n\n\n\n\n\n\n\n\n\nt1scs1\nt1scs2\nt1scs3\nt1scs4\nt1scs5\nt1scs6\nt1scs7\nt1scs8\nt1scs9\nt1scs10\n...\nt3cbq12\nt3cbq13\nt3cbq14\nt3cbq15\nt3ssq1\nt3ssq2\nt3ssq3\nt3ssq4\nt3ssq5\nt3ssq6\n\n\n\n\n0\n3\n4\n4\n1\n3\n3\n3\n2\n2\n2\n...\n2\n2\n4\n1\n4\n4\n5\n4\n4\n5\n\n\n\n\n1 rows × 99 columns\n\n\n\n\nSe observa que para las variables seleccionadas, los valores se invirtieron: - Valor 1 cambió al valor 5 - Valor 2 cambió al valor 4 - Valor 3 sigue siendo el mismo - Valor 4 cambió al valor 2 - Valor 5 cambió al valor 1\nReemplezando los valores en el df orginal\n\ndf = df_inverted\n\nCalculad las puntuaciones totales de las escalas (autocompasión, burnout y apoyo social percibido). Guardad estas nuevas variables en la base de datos.\n\nautocompasion1 = df.filter(regex='^t1scs')\nautocompasion2 = df.filter(regex='^t2scs')\nautocompasion3 = df.filter(regex='^t3scs')\nburnout1 = df.filter(regex='^t1cbq')\nburnout2 = df.filter(regex='^t2cbq')\nburnout3 = df.filter(regex='^t3cbq')\napoyo_social1 = df.filter(regex='^t1ssq')\napoyo_social2 = df.filter(regex='^t2ssq')\napoyo_social3 = df.filter(regex='^t3ssq')\n\n\ndf['autocompasion1'] = autocompasion1.sum(axis=1)\ndf['autocompasion2'] = autocompasion2.sum(axis=1)\ndf['autocompasion3'] = autocompasion3.sum(axis=1)\ndf['burnout1'] = burnout1.sum(axis=1)\ndf['burnout2'] = burnout2.sum(axis=1)\ndf['burnout3'] = burnout3.sum(axis=1)\ndf['apoyo_social1'] = apoyo_social1.sum(axis=1)\ndf['apoyo_social2'] = apoyo_social2.sum(axis=1)\ndf['apoyo_social3'] = apoyo_social3.sum(axis=1)\ndf.head()\n\n\n\n\n\n\n\n\n\nt1scs1\nt1scs2\nt1scs3\nt1scs4\nt1scs5\nt1scs6\nt1scs7\nt1scs8\nt1scs9\nt1scs10\n...\nt3ssq6\nautocompasion1\nautocompasion2\nautocompasion3\nburnout1\nburnout2\nburnout3\napoyo_social1\napoyo_social2\napoyo_social3\n\n\n\n\n0\n3\n4\n4\n1\n3\n3\n3\n2\n2\n2\n...\n5\n32\n26\n32\n27\n29\n32\n24\n25\n26\n\n\n1\n1\n4\n4\n2\n5\n2\n4\n1\n1\n4\n...\n5\n31\n28\n33\n28\n23\n28\n25\n28\n25\n\n\n2\n1\n5\n5\n1\n4\n5\n5\n1\n2\n2\n...\n5\n34\n32\n29\n26\n28\n24\n30\n30\n30\n\n\n3\n3\n3\n4\n2\n3\n3\n3\n2\n3\n4\n...\n4\n38\n35\n34\n26\n25\n30\n24\n25\n26\n\n\n4\n3\n3\n5\n1\n3\n4\n2\n2\n3\n4\n...\n5\n36\n32\n31\n25\n24\n30\n30\n30\n30\n\n\n\n\n5 rows × 108 columns\n\n\n\n\nCon las nuevas variables calculadas en el apartado anterior, haced una descripción estadística de las mismas en los tres momentos de estudio. Una posibilidad de tabla resumen sería la plantilla mostrada en la Tabla 2.\n\ndf_new = df[['autocompasion1', 'burnout1', 'apoyo_social1',\n             'autocompasion2', 'burnout2', 'apoyo_social2',\n             'autocompasion3', 'burnout3', 'apoyo_social3']]\n\n\nstat = df_new.describe()\nstat\n\n\n\n\n\n\n\n\n\nautocompasion1\nburnout1\napoyo_social1\nautocompasion2\nburnout2\napoyo_social2\nautocompasion3\nburnout3\napoyo_social3\n\n\n\n\ncount\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n258.000000\n\n\nmean\n34.228682\n33.155039\n25.290698\n34.720930\n33.713178\n25.236434\n34.337209\n33.689922\n25.344961\n\n\nstd\n4.661085\n6.800034\n3.954605\n4.181629\n7.077331\n4.286699\n4.796912\n7.347197\n4.084848\n\n\nmin\n16.000000\n21.000000\n12.000000\n19.000000\n22.000000\n8.000000\n12.000000\n21.000000\n7.000000\n\n\n25%\n32.000000\n28.000000\n23.000000\n32.000000\n29.000000\n23.000000\n32.000000\n29.000000\n23.000000\n\n\n50%\n34.500000\n33.000000\n26.000000\n35.000000\n33.500000\n26.000000\n34.000000\n33.000000\n26.000000\n\n\n75%\n38.000000\n37.000000\n28.000000\n37.000000\n38.000000\n29.000000\n37.000000\n37.750000\n29.000000\n\n\nmax\n45.000000\n56.000000\n30.000000\n45.000000\n64.000000\n30.000000\n47.000000\n68.000000\n30.000000",
    "crumbs": [
      "Projects",
      "1. Classification Dimensions Analysis"
    ]
  },
  {
    "objectID": "project1.html#evolución-a-lo-largo-del-tiempo",
    "href": "project1.html#evolución-a-lo-largo-del-tiempo",
    "title": "1. Classification Dimensions Analysis",
    "section": "Evolución a lo largo del tiempo",
    "text": "Evolución a lo largo del tiempo\nComplementad el análisis anterior con gráficos adecuados que permitan evaluar la evolución de las 3 dimensiones a lo largo del tiempo.\n\nmean_values_autocomp1 = stat.loc['mean', 'autocompasion1']\nmean_values_burnout1 = stat.loc['mean', 'burnout1']\nmean_values_apoyo1 = stat.loc['mean', 'apoyo_social1']\nmean_values_autocomp2 = stat.loc['mean', 'autocompasion2']\nmean_values_burnout2 = stat.loc['mean', 'burnout2']\nmean_values_apoyo2 = stat.loc['mean', 'apoyo_social2']\nmean_values_autocomp3 = stat.loc['mean', 'autocompasion3']\nmean_values_burnout3 = stat.loc['mean', 'burnout3']\nmean_values_apoyo3 = stat.loc['mean', 'apoyo_social3']\n\n\n# Create a new DataFrame with the mean values\nmean_df = pd.DataFrame({\n    'autocompasion': [mean_values_autocomp1, mean_values_autocomp2, mean_values_autocomp3],\n    'burnout': [mean_values_burnout1, mean_values_burnout2, mean_values_burnout3],\n    'apoyo_social': [mean_values_apoyo1, mean_values_apoyo2, mean_values_apoyo3]\n}, index=['Línea Base', '3 Meses', '6 Meses'])\nmean_df\n\n\n\n\n\n\n\n\n\nautocompasion\nburnout\napoyo_social\n\n\n\n\nLínea Base\n34.228682\n33.155039\n25.290698\n\n\n3 Meses\n34.720930\n33.713178\n25.236434\n\n\n6 Meses\n34.337209\n33.689922\n25.344961\n\n\n\n\n\n\n\n\n\n# Plotting with seaborn\nplt.figure(figsize=(8, 6))\nfor column in mean_df.columns:\n    sns.lineplot(x=mean_df.index, y=mean_df[column], marker='o',label=column)\n    for i, value in enumerate(mean_df[column]):\n        plt.annotate(f'{value:.2f}', (mean_df.index[i], value), textcoords=\"offset points\", xytext=(0,5), ha='center', fontsize=8)\n\n\nplt.title('Media de las dimensiones a lo largo del tiempo')\nplt.ylabel('Media')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nAutocompasión e Burnout: Con relación a la línea base, se observa que el promedio aumenta en 3 meses y luego disminuye en 6 meses.\nApoyo Social: Con relación a la línea base, se observa que el promedio disminuye en 3 meses y luego aumenta en 6 meses.\nIncluso con la dimensión de apoyo social reduciendo el promedio en 3 meses, ambas dimensiones terminaron en 6 meses con un promedio superior al de referencia.",
    "crumbs": [
      "Projects",
      "1. Classification Dimensions Analysis"
    ]
  },
  {
    "objectID": "project1.html#boxplots-for-each-dimension-over-time",
    "href": "project1.html#boxplots-for-each-dimension-over-time",
    "title": "1. Classification Dimensions Analysis",
    "section": "Boxplots for Each Dimension Over Time",
    "text": "Boxplots for Each Dimension Over Time\n\n# Create separate boxplots for each dimension\nfig, axes = plt.subplots(ncols=3, figsize=(18, 6))\n\ndimensions = ['autocompasion', 'burnout', 'apoyo_social']\n\nfor i, dim in enumerate(dimensions):\n    cols = [col for col in df_new.columns if dim in col]\n    df_dim = df_new[cols]\n    \n    # Melt the DataFrame for boxplot\n    df_dim_melted = pd.melt(df_dim, var_name='Time', value_name='Value')\n\n    # Create a boxplot for the current dimension\n    ax = sns.boxplot(x='Time', y='Value', data=df_dim_melted, ax=axes[i])\n    ax.set_title(f'Boxplot for {dim.capitalize()} Over Time')\n    ax.set_xlabel('Time')\n    ax.set_ylabel(f'{dim} Value')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nLos diagramas de caja anteriores muestran que los datos mantuvieron el mismo patrón a lo largo del tiempo. Lo que llama la atención en este análisis son los valores atípicos.\n\nAutocompassion:\n\nLos valores atípicos aumentaron con el tiempo, tanto para valores altos como bajos. Esto muestra que para algunas personas hubo un gran cambio en la autocompasión a lo largo del tiempo.\n\n\n\nBurnout:\n\nLos valores atípicos aumentaron con el tiempo hasta alcanzar valores de aproximadamente 70. Esto muestra que para algunas personas hubo un aumento en el agotamiento con el tiempo.\n\n\n\nApoyo Social:\n\nLos valores atípicos disminuyeron, pero los valores atípicos que aparecieron tuvieron valores más bajos con el tiempo. Esto muestra que para unas pocas personas hubo una gran disminución en el apoyo social con el tiempo.",
    "crumbs": [
      "Projects",
      "1. Classification Dimensions Analysis"
    ]
  },
  {
    "objectID": "project1.html#correlation-matrix",
    "href": "project1.html#correlation-matrix",
    "title": "1. Classification Dimensions Analysis",
    "section": "Correlation Matrix",
    "text": "Correlation Matrix\nEstudiad todas las posibles correlaciones entre las dimensiones obtenidas en los apartados anteriores con indicadores adecuados y de forma separada para cada momento. Complementad estos análisis sobre correlaciones con gráficos adecuados.\n\ncorrelation_matrix = df_new.corr()\ncorrelation_matrix\n\n\n\n\n\n\n\n\n\nautocompasion1\nburnout1\napoyo_social1\nautocompasion2\nburnout2\napoyo_social2\nautocompasion3\nburnout3\napoyo_social3\n\n\n\n\nautocompasion1\n1.000000\n0.291790\n-0.263056\n0.626345\n0.272463\n-0.220826\n0.584403\n0.239546\n-0.192583\n\n\nburnout1\n0.291790\n1.000000\n-0.334625\n0.200765\n0.753248\n-0.213504\n0.199748\n0.723706\n-0.213876\n\n\napoyo_social1\n-0.263056\n-0.334625\n1.000000\n-0.178608\n-0.352775\n0.766694\n-0.162923\n-0.310256\n0.800210\n\n\nautocompasion2\n0.626345\n0.200765\n-0.178608\n1.000000\n0.200418\n-0.143044\n0.631075\n0.162322\n-0.149015\n\n\nburnout2\n0.272463\n0.753248\n-0.352775\n0.200418\n1.000000\n-0.317496\n0.196098\n0.782726\n-0.295495\n\n\napoyo_social2\n-0.220826\n-0.213504\n0.766694\n-0.143044\n-0.317496\n1.000000\n-0.121213\n-0.224737\n0.774622\n\n\nautocompasion3\n0.584403\n0.199748\n-0.162923\n0.631075\n0.196098\n-0.121213\n1.000000\n0.271480\n-0.132453\n\n\nburnout3\n0.239546\n0.723706\n-0.310256\n0.162322\n0.782726\n-0.224737\n0.271480\n1.000000\n-0.280094\n\n\napoyo_social3\n-0.192583\n-0.213876\n0.800210\n-0.149015\n-0.295495\n0.774622\n-0.132453\n-0.280094\n1.000000\n\n\n\n\n\n\n\n\n\n# Plot a heatmap for better visualization of correlations\nplt.figure(figsize=(8, 6))\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5)\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\n\n\n\n\n\nLa correlación negativa más fuerte (-0,35) se observó entre “apoyo_social1” y “burnout2”. La segunda correlación negativa más grande (-0,33) se produce entre “apoyo_social1” y “burnout1”, seguida de la tercera correlación negativa más grande (-0,32) entre “apoyo_social2” y “burnout2”.\nLa correlación positiva más significativa (0,80) se encontró entre “apoyo_social1” y “apoyo_social3”. La segunda correlación positiva más alta (0,78) se observa entre “burnout2” y “burnout3”, y la tercera correlación positiva más alta (0,77) es entre “apoyo_social1” y “apoyo_social2”.\nEn cuanto a las tendencias, cuando disminuye la percepción de apoyo social, hay una tendencia asociada a que el nivel de burnout disminuya, tanto en el mismo momento como en los tres meses siguientes. Por el contrario, cuando aumenta el apoyo social percibido, a esta tendencia le sigue un aumento continuo en los meses siguientes. De manera similar, un aumento en el nivel de burnout tiende a ir seguido de un aumento durante los próximos tres meses.\nEstos patrones sugieren una fuerte asociación entre la percepción de apoyo social y el nivel de agotamiento. Cuando no hay signos de agotamiento, la necesidad de apoyo social puede no ser tan apremiante. Sin embargo, el aumento en la percepción de apoyo social puede indicar un posible aumento simultáneo en el nivel de burnout.\n\n# Plot all three heatmaps in a single row\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor i, (time_df, time_label) in enumerate(zip([df[['autocompasion1', 'burnout1', 'apoyo_social1']],\n                                               df[['autocompasion2', 'burnout2', 'apoyo_social2']],\n                                               df[['autocompasion3', 'burnout3', 'apoyo_social3']]], \n                                              ['Línea Base', '3 meses', '6 meses']), 1):\n    correlation_matrix = time_df.corr()\n    \n    # Plot a heatmap on each subplot\n    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5, ax=axes[i-1])\n    axes[i-1].set_title(f'{time_label}')\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAutocompasion - Tiene una correlación positiva con el burnout. Cuando aumenta la autocompasión, el agotamiento también tiende a aumentar - Tiene una correlación negativa con el apoyo social. Cuando la autocompasión aumenta, el apoyo social tiende a disminuir.\nBurnout - Tiene una correlación positiva con la automapasión. Cuando aumenta el agotamiento, la autocompasión también tiende a aumentar - Tiene una correlación negativa con el apoyo social. Cuando aumenta el burnout, el apoyo social tiende a disminuir\nApoyo Social: - Tiene una correlación negativa con la automapasión. Cuando el apoyo social disminuye, la autocompasión también tiende a disminuir - Tiene una correlación negativa con el apoyo social. Cuando el apoyo social disminuye, el agotamiento tiende a disminuir\nCread una función que clasifique cada individuo de la muestra de acuerdo al siguiente criterio:\nSi t3=t1:estable Si t3&lt;t1:inestable positivo (SCS y CBQ) o negativo (BPSSQ) Si t3&gt;t1:inestable negativo (SCS y CBQ) o positivo (BPSSQ) Utilizad la nueva función para clasificar a los participantes en el estudio por separado por cada dimensión de interés (autocompasión, burnout y apoyo social percibido). Guardad estas clasificaciones como nuevas variables de la base de datos.\n\n# Función para clasificar a cada individuo\ndef clasificar_compasion(row):\n    if row['autocompasion3'] == row['autocompasion1']:\n        return 'estable'\n    elif row['autocompasion3'] &lt; row['autocompasion1']:\n        return 'inestable positivo'\n    else:\n        return 'inestable negativo'\n\n# Aplicar la función a la dimensión de autocompasión y crear nueva variable\ndf_new['clasificacion_autocompasion'] = df_new.apply(clasificar_compasion, axis=1)\n\n/var/folders/dq/jx6zt2hd4lx90cd8_tbzmqs00000gn/T/ipykernel_65177/3400645821.py:11: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n# Repetir el proceso para las otras dimensiones (burnout y apoyo social)\n# Función para clasificar burnout\ndef clasificar_burnout(row):\n    if row['burnout3'] == row['burnout1']:\n        return 'estable'\n    elif row['burnout3'] &lt; row['burnout1']:\n        return 'inestable positivo'\n    else:\n        return 'inestable negativo'\n\n# Aplicar la función a la dimensión de burnout y crear nueva variable\ndf_new['clasificacion_burnout'] = df_new.apply(clasificar_burnout, axis=1)\n\n/var/folders/dq/jx6zt2hd4lx90cd8_tbzmqs00000gn/T/ipykernel_65177/2911693610.py:12: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n# Función para clasificar apoyo social\ndef clasificar_apoyo_social(row):\n    if row['apoyo_social3'] == row['apoyo_social1']:\n        return 'estable'\n    elif row['apoyo_social3'] &lt; row['apoyo_social1']:\n        return 'inestable negativo'\n    else:\n        return 'inestable positivo'\n\n# Aplicar la función a la dimensión de apoyo social y crear nueva variable\ndf_new['clasificacion_apoyo_social'] = df_new.apply(clasificar_apoyo_social, axis=1)\ndf_new.head()\n\n/var/folders/dq/jx6zt2hd4lx90cd8_tbzmqs00000gn/T/ipykernel_65177/844085262.py:11: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\n\nautocompasion1\nburnout1\napoyo_social1\nautocompasion2\nburnout2\napoyo_social2\nautocompasion3\nburnout3\napoyo_social3\nclasificacion_autocompasion\nclasificacion_burnout\nclasificacion_apoyo_social\n\n\n\n\n0\n32\n27\n24\n26\n29\n25\n32\n32\n26\nestable\ninestable negativo\ninestable positivo\n\n\n1\n31\n28\n25\n28\n23\n28\n33\n28\n25\ninestable negativo\nestable\nestable\n\n\n2\n34\n26\n30\n32\n28\n30\n29\n24\n30\ninestable positivo\ninestable positivo\nestable\n\n\n3\n38\n26\n24\n35\n25\n25\n34\n30\n26\ninestable positivo\ninestable negativo\ninestable positivo\n\n\n4\n36\n25\n30\n32\n24\n30\n31\n30\n30\ninestable positivo\ninestable negativo\nestable\n\n\n\n\n\n\n\n\n¿Existe relación entre las variables categóricas creadas en el apartado anterior? Realizad todos los análisis bivariantes posibles (escogiendo 2 variables cada vez)\n\ndf_cat = df_new[['clasificacion_autocompasion', 'clasificacion_burnout', 'clasificacion_apoyo_social']]\n\n\n# tabla de contingencia\ncont_tbl_auto_burn = pd.crosstab(df_cat['clasificacion_autocompasion'], df_cat['clasificacion_burnout'])\ncont_tbl_auto_apoy = pd.crosstab(df_cat['clasificacion_autocompasion'], df_cat['clasificacion_apoyo_social'])\ncont_tbl_burn_apoy = pd.crosstab(df_cat['clasificacion_burnout'], df_cat['clasificacion_apoyo_social'])\n\n\n# chi-square y p-value\nchi2, p, _, _ = chi2_contingency(cont_tbl_auto_burn)\n# cramer's v\nV_cramer = np.sqrt(chi2 / (cont_tbl_auto_burn.sum().sum() * (np.min(cont_tbl_auto_burn.shape) - 1)))\n\n# resultados\nprint(\"Autocompasion y Burnout\")\nprint(\" \")\nprint(cont_tbl_auto_burn)\nprint(\" \")\nprint('Chi-Square = {:.2f}'.format(chi2))\nprint('P-Value = {:.4f}'.format(p))      \nprint('Cramer\\'s V = {:.2f}'.format(V_cramer))\n\n# interpretación\nif p &lt; 0.05:\n    print(\"\\nLas variables son dependientes.\")\nelse:\n    print(\"\\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.\")\n\nAutocompasion y Burnout\n \nclasificacion_burnout        estable  inestable negativo  inestable positivo\nclasificacion_autocompasion                                                 \nestable                            3                  19                  15\ninestable negativo                 9                  64                  47\ninestable positivo                11                  39                  51\n \nChi-Square = 5.11\nP-Value = 0.2758\nCramer's V = 0.10\n\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.\n\n\n\n# chi-square y p-value\nchi2, p, _, _ = chi2_contingency(cont_tbl_auto_apoy)\n# cramer's v\nV_cramer = np.sqrt(chi2 / (cont_tbl_auto_apoy.sum().sum() * (np.min(cont_tbl_auto_apoy.shape) - 1)))\n\n\n# resultados\nprint(\"Autocompasion y Apoyo Social\")\nprint(\" \")\nprint(cont_tbl_auto_apoy)\nprint(\" \")\nprint('Chi-Square = {:.2f}'.format(chi2))\nprint('P-Value = {:.4f}'.format(p))      \nprint('Cramer\\'s V = {:.2f}'.format(V_cramer))\n\n# interpretación\nif p &lt; 0.05:\n    print(\"\\nLas variables son dependientes.\")\nelse:\n    print(\"\\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.\")\n\nAutocompasion y Apoyo Social\n \nclasificacion_apoyo_social   estable  inestable negativo  inestable positivo\nclasificacion_autocompasion                                                 \nestable                           11                  14                  12\ninestable negativo                34                  42                  44\ninestable positivo                24                  34                  43\n \nChi-Square = 1.60\nP-Value = 0.8080\nCramer's V = 0.06\n\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.\n\n\n\n# chi-square y p-value\nchi2, p, _, _ = chi2_contingency(cont_tbl_burn_apoy)\n# cramer's v\nV_cramer = np.sqrt(chi2 / (cont_tbl_burn_apoy.sum().sum() * (np.min(cont_tbl_burn_apoy.shape) - 1)))\n\n# resultados\nprint(\"\\nBurnout y Apoyo Social\")\nprint(\" \")\nprint(cont_tbl_burn_apoy)\nprint(\" \")\nprint('Chi-Square = {:.2f}'.format(chi2))\nprint('P-Value = {:.4f}'.format(p))      \nprint('Cramer\\'s V = {:.2f}'.format(V_cramer))\n\n# interpretación\nif p &lt; 0.05:\n    print(\"\\nLas variables son dependientes.\")\nelse:\n    print(\"\\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.\")\n\n\nBurnout y Apoyo Social\n \nclasificacion_apoyo_social  estable  inestable negativo  inestable positivo\nclasificacion_burnout                                                      \nestable                           4                  11                   8\ninestable negativo               31                  47                  44\ninestable positivo               34                  32                  47\n \nChi-Square = 4.82\nP-Value = 0.3060\nCramer's V = 0.10\n\nLas variables son independientes. No hay evidencia suficiente para rechazar la independencia entre las variables.\n\n\nComo todos os P-values são &gt; 0.05, indica que as variáveis são independentes.\nComplementad los análisis bivariantes anteriores con gráficos adecuados para favorecer la inspección visual de las distribuciones conjuntas.\n\n# Melt the DataFrame to have a single column for variable names and values\ndf_melted = pd.melt(df_cat[['clasificacion_autocompasion', 'clasificacion_burnout', 'clasificacion_apoyo_social']], var_name='Variable', value_name='Category')\n\n\n# Get unique combinations of Variable and Category\ncombinations = df_melted.groupby(['Variable', 'Category']).size().reset_index(name='Count')\n\n\n# Create a mosaic chart\nmosaic_data = pd.crosstab(df_melted['Variable'], df_melted['Category'])\nmosaic_data\n\n\n\n\n\n\n\n\nCategory\nestable\ninestable negativo\ninestable positivo\n\n\nVariable\n\n\n\n\n\n\n\nclasificacion_apoyo_social\n69\n90\n99\n\n\nclasificacion_autocompasion\n37\n120\n101\n\n\nclasificacion_burnout\n23\n122\n113\n\n\n\n\n\n\n\n\n\npalette_dimensions = 'Set2'\npalette_status = 'Set3'\n\n# Create subplots\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# Plot the first chart on the left subplot with the specified color palette\nsns.countplot(x='Variable', hue='Category', data=df_melted, ax=axes[0], palette=palette_dimensions)\naxes[0].set_title('Dimensions by Status')\n\n# Plot the second chart on the right subplot with a different color palette\nsns.barplot(x='Category', y='Count', hue='Variable', data=combinations, \n            order=combinations['Category'].unique(), ax=axes[1], palette=palette_status)\naxes[1].set_title('Status by Dimensions')\n\n# Adjust layout to prevent clipping of titles and labels\nplt.tight_layout()\n\n# Show the plots\nplt.show()",
    "crumbs": [
      "Projects",
      "1. Classification Dimensions Analysis"
    ]
  },
  {
    "objectID": "project2.html#objective",
    "href": "project2.html#objective",
    "title": "2. Prediction of Diabetes",
    "section": "",
    "text": "The objective is to predict based on diagnostic measurements whether a patient has diabetes.",
    "crumbs": [
      "Projects",
      "2. Prediction of Diabetes"
    ]
  },
  {
    "objectID": "project2.html#constraints",
    "href": "project2.html#constraints",
    "title": "2. Prediction of Diabetes",
    "section": "",
    "text": "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.",
    "crumbs": [
      "Projects",
      "2. Prediction of Diabetes"
    ]
  },
  {
    "objectID": "project2.html#features",
    "href": "project2.html#features",
    "title": "2. Prediction of Diabetes",
    "section": "",
    "text": "Pregnancies: Number of times pregnant\n\n\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\n\nBloodPressure: Diastolic blood pressure (mm Hg)\n\n\nSkinThickness: Triceps skin fold thickness (mm)\n\n\nInsulin: 2-Hour serum insulin (mu U/ml)\n\n\nBMI: Body mass index (weight in kg/(height in m)^2)\n\n\nDiabetesPedigreeFunction: Diabetes pedigree function\n\n\nAge: Age (years)\n\n\nOutcome: Class variable (0 or 1) 1: Diabetic, 0: Healty",
    "crumbs": [
      "Projects",
      "2. Prediction of Diabetes"
    ]
  },
  {
    "objectID": "project2.html#exploratory-analysis",
    "href": "project2.html#exploratory-analysis",
    "title": "2. Prediction of Diabetes",
    "section": "",
    "text": "#%% Setup\n#Libraries import\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom numpy import sqrt\nfrom numpy import argmax\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, mean_squared_error, roc_curve, RocCurveDisplay, recall_score\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.linear_model import LogisticRegression\n\n#Dataset read\npima = pd.read_csv('./source/diabetes.csv')\n\n#The dataset has 768 rows and 9 columns\npima.shape\npima.head()\n\n\n#This output shows that all dataset features are numeric.\npima.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n\n\n\n#This function show the main statistics for the features. \npima.describe().T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nPregnancies\n768.0\n3.845052\n3.369578\n0.000\n1.00000\n3.0000\n6.00000\n17.00\n\n\nGlucose\n768.0\n120.894531\n31.972618\n0.000\n99.00000\n117.0000\n140.25000\n199.00\n\n\nBloodPressure\n768.0\n69.105469\n19.355807\n0.000\n62.00000\n72.0000\n80.00000\n122.00\n\n\nSkinThickness\n768.0\n20.536458\n15.952218\n0.000\n0.00000\n23.0000\n32.00000\n99.00\n\n\nInsulin\n768.0\n79.799479\n115.244002\n0.000\n0.00000\n30.5000\n127.25000\n846.00\n\n\nBMI\n768.0\n31.992578\n7.884160\n0.000\n27.30000\n32.0000\n36.60000\n67.10\n\n\nDiabetesPedigreeFunction\n768.0\n0.471876\n0.331329\n0.078\n0.24375\n0.3725\n0.62625\n2.42\n\n\nAge\n768.0\n33.240885\n11.760232\n21.000\n24.00000\n29.0000\n41.00000\n81.00\n\n\nOutcome\n768.0\n0.348958\n0.476951\n0.000\n0.00000\n0.0000\n1.00000\n1.00\n\n\n\n\n\n\n\n\n\n#This function shows that any of the features has null values\npima.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64",
    "crumbs": [
      "Projects",
      "2. Prediction of Diabetes"
    ]
  }
]